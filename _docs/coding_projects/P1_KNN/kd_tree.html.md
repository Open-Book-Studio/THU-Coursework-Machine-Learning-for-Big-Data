---
author: "\u53F6\u74A8\u94ED (2024214500) \n ycm24@mails.tsinghua.edu.cn"
bibliography:
- ../../references.bib
date: '2024-10-21'
date-format: full
format:
  docx: default
  gfm: default
  html:
    code-fold: false
highlight-style: pygments
jupyter: python3
lang: zh
number-sections: true
output-file: kd_tree.html
subtitle: "\u5927\u6570\u636E\u673A\u5668\u5B66\u4E60\u8BFE\u7A0B\u7B2C\u4E00\u6B21\
  \u5B9E\u9A8C\u9879\u76EE"
title: "\u6DF1\u5165\u63A2\u7D22KD\u6811\u6570\u636E\u7ED3\u6784\u5B9E\u73B0\u7684\
  KNN\u7B97\u6CD5\u53CA\u5176\u5728\u624B\u5199\u6570\u5B57\u8BC6\u522B\u4E2D\u7684\
  \u5E94\u7528"
toc: true

---



<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->

<img src="../../thu_sigs_logo.png" alt="æ¸…åæ·±ç ”é™¢-æ¨ª" style="zoom:50%;" />

ä»£ç å¤ç°è¯´æ˜
```shell
pip install git+https://github.com/Open-Book-Studio/THU-Coursework-Machine-Learning-for-Big-Data.git
pip install ray optuna seaborn matplotlib sklearn
```
æˆ‘ä»¬çš„ä»£ç å¯¼å‡ºä¸ºäº†pythonæ¨¡å—å½¢å¼
```python
from thu_big_data_ml_tree import FastKDTree
```

## å®éªŒç›®çš„
> è€å¸ˆç»™æˆ‘ä»¬çš„è¦æ±‚æ˜¯
> 1. å®Œæˆ KD æ ‘ç®—æ³•ï¼Œå¹¶åˆ©â½¤å®ç°çš„ç®—æ³•å®Œæˆæ•°å­—è¯†åˆ«ä»»åŠ¡
> 2. å¯¹æ‰€å»ºæ¨¡å‹è¿›è¡Œåˆ†æè¯„åˆ¤ã€‚

æˆ‘ä»¬ä¸ä»…å®Œæˆä»¥ä¸Šå†…å®¹ï¼Œè¿˜è¿›è¡Œäº†
1. å‚è€ƒè°·æ­Œè°ƒå‚æ‰‹å†Œï¼Œä½¿ç”¨ç§‘å­¦çš„å®éªŒè®¾è®¡æ¥å¯¹KNNåˆ†ç±»ç®—æ³•çš„å…ƒå‚æ•°è¿›è¡Œæœç´¢ï¼Œä»è€Œå®ç°æ›´é«˜çš„åˆ†ç±»ç²¾åº¦ã€‚
2. å‚è€ƒå‰æ²¿è®ºæ–‡ï¼Œå°è¯•ä¿®æ”¹KDæ ‘çš„è®­ç»ƒç­–ç•¥ï¼Œä»è€Œå¯¹KDæ ‘çš„æ¨ç†é€Ÿåº¦è¿›è¡Œæ”¹è¿›ã€‚

## å®éªŒæ•°æ®
> MNIST æ•°æ®åº“æ˜¯ç”± Yann et. al. æä¾›çš„â¼¿å†™æ•°å­—æ•°æ®åº“â½‚ä»¶, å®˜ç½‘åœ°å€ä¸º http://yann.lecun.com/exdb/mnist/ã€‚
> ä¸»è¦åŒ…å«äº† 60000 å¼ çš„è®­ç»ƒå›¾åƒå’Œ 10000 å¼ çš„æµ‹è¯•å›¾åƒ
> ```python
> from sklearn.datasets import fetch_openml
> from sklearn.model_selection import train_test_split
> from sklearn.neighbors import KNeighborsClassifier
> from sklearn.metrics import accuracy_score
> import numpy as np
> # è·å–MNISTæ•°æ®é›†,å¹¶æŠ½æ ·ä¸€éƒ¨åˆ†æ•°æ®ä»¥ä¾¿åç»­çš„è®¡ç®—
> idx = np.random.choice(70000,5000,replace=False)
> mnist = fetch_openml("mnist_784")
> X, y = mnist.data.to_numpy(), mnist.target.to_numpy().astype('int')
> X = X[idx]
> y = y[idx]
> # åˆ’åˆ†æ•°æ®é›†ä¸ºè®­ç»ƒé›†å’Œæµ‹è¯•é›†
> X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
> 
> ```

ä»¥ä¸Šä»£ç æœ‰å‡ ä¸ªå°é—®é¢˜ï¼Œæˆ‘ä»¬éœ€è¦æ”¹è¿›ä¸€ä¸‹
1. ç”±äºç½‘ç»œç¯å¢ƒé—®é¢˜ï¼Œfetch_openml("mnist_784") æ˜¯æ— æ³•è·‘é€šçš„ï¼Œä¼šå¡æ­»ã€‚
äº‹å®ä¸Šï¼Œç»™sklearnè´¡çŒ®è¿‡ä»£ç çš„åŒå­¦å¯èƒ½çŸ¥é“ï¼Œsklearnè¿˜æœ‰ä¸€ä¸ªload_digitsæ•°æ®é›†ï¼Œè¿™ä¸ªæ•°æ®é›†æ˜¯sklearn CIï¼ˆæŒç»­é›†æˆï¼‰æµ‹è¯•ç”¨ä¾‹çš„ä¸€éƒ¨åˆ†ã€‚è¿™ä¸ªå›å½’æµ‹è¯•é€šè¿‡æµ‹è¯•è´¡çŒ®è€…çš„æ–°åšçš„æ”¹è¿›æ˜¯å¦å¯¼è‡´æ€§èƒ½ä¸å¦‚ä»¥å‰çš„ç‰ˆæœ¬ï¼Œæ¥å†³å®šæ˜¯å¦æ¥å—æ›´æ”¹ã€‚
å› æ­¤ï¼Œæˆ‘ä»¬ä½¿ç”¨load_digitsæ•°æ®é›†ä»£æ›¿mnist_784æ•°æ®é›†æ¥å®Œæˆè¿™ä¸ªé¡¹ç›®ã€‚

https://scikit-learn.org/1.5/modules/generated/sklearn.datasets.load_digits.html

2. åˆ’åˆ†æ•°æ®é›†æ—¶ï¼Œtrain_test_splitåº”å½“ä½¿ç”¨stratifyå‚æ•°ï¼Œä»¥ç¡®ä¿æ¯ä¸€ç±»æ ·æœ¬çš„æ¯”ä¾‹ç›¸åŒã€‚
3. importè¿‡å¤šï¼Œåº”è¯¥åªå¯¼å…¥éœ€è¦çš„æ¨¡å—ã€‚

::: {#cell-7 .cell vscode='{"languageId":"python"}' execution_count=1}
``` {.python .cell-code}
from sklearn.datasets import load_digits
dataset_dict = load_digits()
dataset_dict.keys()
```

::: {.cell-output .cell-output-display execution_count=1}
```
dict_keys(['data', 'target', 'frame', 'feature_names', 'target_names', 'images', 'DESCR'])
```
:::
:::


::: {#cell-8 .cell vscode='{"languageId":"python"}' execution_count=2}
``` {.python .cell-code}
import numpy as np
X:np.array = dataset_dict['data']
y:np.array = dataset_dict['target']
X.shape, X.dtype, y.shape, y.dtype
```

::: {.cell-output .cell-output-display execution_count=2}
```
((1797, 64), dtype('float64'), (1797,), dtype('int64'))
```
:::
:::


åˆ’åˆ†æ•°æ®é›†ä¸ºè®­ç»ƒé›†å’Œæµ‹è¯•é›†

::: {#cell-10 .cell vscode='{"languageId":"python"}' execution_count=3}
``` {.python .cell-code}
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, 
                                                    stratify=y)
len(X_train), len(X_test)
```

::: {.cell-output .cell-output-display execution_count=3}
```
(1437, 360)
```
:::
:::


## å®éªŒå†…å®¹
### KNNå’ŒKDæ ‘çš„å…³ç³»æ˜¯ä»€ä¹ˆï¼Ÿä»€ä¹ˆå«åŸºäºKDæ ‘çš„KNNç®—æ³•ï¼Ÿ

åœ¨æˆ‘ä»¬å¼€å§‹å®éªŒå†…å®¹ä¹‹å‰ï¼Œæœ‰å¿…è¦æ¾„æ¸…è¿™ä¸€ç†è®ºä¸Šçš„æ¦‚å¿µã€‚

KNNï¼ˆK-Nearest Neighborï¼‰ç®—æ³•æ˜¯ä¸€ç§åŸºæœ¬çš„æœºå™¨å­¦ä¹ ç®—æ³•ï¼Œæ—¢å¯ä»¥ç”¨äºåˆ†ç±»ä¹Ÿå¯ä»¥ç”¨äºå›å½’ã€‚
å¯¹äºæ–°çš„ä¸€ä¸ªæµ‹è¯•æ ·æœ¬ï¼ˆæœªçŸ¥ç±»åˆ«æˆ–æ ‡ç­¾å€¼ï¼‰æ¥è¯´ï¼Œå®ƒå’Œè®­ç»ƒé›†ä¸­æ¯ä¸€ä¸ªæ ·æœ¬éƒ½æœ‰è·ç¦»ï¼Œä»è€Œå­˜åœ¨ç¦»æµ‹è¯•æ ·æœ¬æœ€è¿‘çš„Kä¸ªæ ·æœ¬ï¼ˆå½“ç„¶è®­ç»ƒé›†è¦å¤§äºKå•¦ï¼‰ï¼Œç„¶åæ ¹æ®è¿™äº›æ ·æœ¬çš„å·²çŸ¥æ ‡ç­¾æ¥å†³å®šæµ‹è¯•æ ·æœ¬çš„æ ‡ç­¾ã€‚

> æˆ‘ä»Šå¤©å­¦ä¹ çš„ã€Šè‡ªç„¶è¾©è¯æ³•è¯¾ã€‹ä¸Šæ­£å¥½è®²åˆ°ä¸€ä¸ªå“²å­¦æ¦‚å¿µå«åšâ€œç±»æ¯”æ¨ç†â€ä¸â€œæ¼”ç»æ¨ç†â€ã€‚å¤å¸Œè…Šçš„å“²å­¦å®¶ä»¬åˆ™å‘å±•äº†å½¢å¼é€»è¾‘ï¼Œæ¯”å¦‚äºšé‡Œå£«å¤šå¾·çš„ä¸‰æ®µè®ºï¼Œæˆ‘ä»¬åœ¨ã€Šæ•°ç†é€»è¾‘å¯¼è®ºã€‹è¯¾ä¸Šè¿˜äº†è§£äº†ç½—ç´ ã€å“¥å¾·å°”ç­‰äººå¯¹æ•´å¥—é€»è¾‘çš„è¿›ä¸€æ­¥å‘å±•ã€‚è€Œä¸­å›½å¤ä»£çš„å…ˆè´¤å¾ˆå–œæ¬¢ç±»æ¯”æ¨ç†ï¼Œæ¯”å¦‚å­Ÿå­è¦æå€¡â€œèˆç”Ÿè€Œå–ä¹‰è€…ä¹Ÿâ€ï¼Œååä¸å’Œä½ è®ºè¯ä¸ºä»€ä¹ˆè¦èˆç”Ÿå–ä¹‰ï¼ˆåæ–‡ä¹Ÿæœ‰ä¸€ç‚¹è®ºè¯ï¼‰ï¼Œè€Œæ˜¯å…ˆè·Ÿä½ è¯´ä»–è§‚å¯Ÿåˆ°äº†â€œäºŒè€…ä¸å¯å¾—å…¼ï¼Œèˆé±¼è€Œå–ç†ŠæŒè€…ä¹Ÿã€‚â€ï¼Œç„¶åä»–è®¤ä¸ºè¿™ä¸¤ä¸ªäº‹æƒ…å¾ˆåƒï¼Œç„¶åå‘Šè¯‰ä½ æ‰€ä»¥è¦èˆç”Ÿå–ä¹‰ï¼›åˆæ¯”å¦‚å­Ÿå­æƒ³è¦è¯´â€œå¤©å°†é™å¤§ä»»äºæ˜¯äººä¹Ÿï¼Œå¿…å…ˆè‹¦å…¶å¿ƒå¿—â€ï¼Œä»–å…ˆç»™äº†ä½ ä¸€ä¸ªè®­ç»ƒé›†ï¼Œè¯´å¥½å¤šâ€œé™å¤§ä»»â€çš„â€œäººâ€éƒ½æ˜¯è¢«â€œè‹¦å…¶å¿ƒå¿—çš„â€ã€‚è¿™ä¸ªæ¨ç†çœ‹èµ·æ¥å¾ˆæ‰¯ï¼Œå®é™…ä¸Šä¹Ÿæ˜¯ä¹Ÿæ˜¯æœ‰ä¸€å®šçš„ç»Ÿè®¡æ„ä¹‰çš„ã€‚

è€ŒKDæ ‘ï¼ˆk-dimensional treeï¼‰æ˜¯ä¸€ç§ç”¨äºç»„ç»‡kç»´ç©ºé—´æ•°æ®çš„æ ‘å½¢æ•°æ®ç»“æ„ï¼Œå®ƒæ˜¯ä¸€ç§ç‰¹æ®Šçš„äºŒå‰æ ‘ã€‚KDæ ‘å°†kç»´ç©ºé—´è¿›è¡Œåˆ†å‰²ï¼Œæ¯ä¸ªèŠ‚ç‚¹ä»£è¡¨ä¸€ä¸ªkç»´è¶…çŸ©å½¢åŒºåŸŸã€‚KDæ ‘çš„ä¸»è¦ä½œç”¨æ˜¯åœ¨é«˜ç»´ç©ºé—´ä¸­å¿«é€Ÿåœ°è¿›è¡Œæœ€è¿‘é‚»æŸ¥æ‰¾ï¼Œå®ƒèƒ½å¤Ÿæ˜¾è‘—å‡å°‘åœ¨KNNç®—æ³•ä¸­è®¡ç®—æ‰€æœ‰è®­ç»ƒæ ·æœ¬ä¸æµ‹è¯•æ ·æœ¬ä¹‹é—´è·ç¦»çš„éœ€æ±‚ï¼Œä»è€Œæé«˜æ•ˆç‡ã€‚

KNNä¸ä¸€å®šè¦ä½¿ç”¨KDæ ‘æ¥è¿›è¡Œè¿‘é‚»æœç´¢ï¼Œäº‹å®ä¸Šè¿˜æœ‰å…¶ä»–æ›´åŠ é«˜æ•ˆçš„æ•°æ®ç»“æ„ï¼Œæ¯”å¦‚Ball Treeã€‚å¦‚æœæˆ‘ä»¬è¯´é»˜è®¤çš„KNNæ˜¯ç”¨æš´åŠ›æ–¹æ³•è®¡ç®—æ‰€æœ‰è·ç¦»çš„é€ä¸€æ¯”è¾ƒçš„è¯ï¼Œæˆ‘ä»¬å¯ä»¥è¯´KDæ ‘ä¸æ˜¯KNNç®—æ³•çš„ä¸€éƒ¨åˆ†ï¼Œè€Œæ˜¯KNNç®—æ³•çš„ä¸€ä¸ªä¼˜åŒ–å·¥å…·ï¼Œç”¨äºåœ¨é«˜ç»´ç©ºé—´ä¸­å¿«é€ŸæŸ¥æ‰¾æœ€è¿‘é‚»ã€‚

### åŸºäºsklearnçš„KNNç®—æ³•å®ç°æ‰‹å†™æ•°å­—è¯†åˆ«

::: {#cell-13 .cell vscode='{"languageId":"python"}'}
``` {.python .cell-code}
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score
# åˆ›å»ºKNeighborsClassifieræ¨¡å‹ï¼Œä½¿ç”¨kdæ ‘ä½œä¸ºæœç´¢ç®—æ³•
knn = KNeighborsClassifier(n_neighbors=3, algorithm='kd_tree')

# åœ¨è®­ç»ƒé›†ä¸Šè®­ç»ƒæ¨¡å‹
knn.fit(X_train, y_train)

# åœ¨æµ‹è¯•é›†ä¸Šè¿›è¡Œé¢„æµ‹
y_pred = knn.predict(X_test)

# è¯„ä¼°æ¨¡å‹æ€§èƒ½
accuracy = accuracy_score(y_test, y_pred)
print(f"KNN Accuracy: {accuracy * 100:.2f}%")
```

::: {.cell-output .cell-output-stdout}
```
KNN Accuracy: 98.61%
```
:::
:::


### è‡ªå·±å®ç°KDæ ‘

---

[source](https://github.com/Open-Book-Studio/THU-Coursework-Machine-Learning-for-Big-Data/blob/main/thu_big_data_ml/tree.py#L27){target="_blank" style="float:right; font-size:smaller"}

### euclidean_distance

>      euclidean_distance (x1, x2)


---

[source](https://github.com/Open-Book-Studio/THU-Coursework-Machine-Learning-for-Big-Data/blob/main/thu_big_data_ml/tree.py#L17){target="_blank" style="float:right; font-size:smaller"}

### build_kd_tree

>      build_kd_tree (X, depth=0)


---

[source](https://github.com/Open-Book-Studio/THU-Coursework-Machine-Learning-for-Big-Data/blob/main/thu_big_data_ml/tree.py#L9){target="_blank" style="float:right; font-size:smaller"}

### Node

>      Node (data, left=None, right=None)

*Initialize self.  See help(type(self)) for accurate signature.*


::: {#cell-18 .cell vscode='{"languageId":"python"}'}
``` {.python .cell-code}
# è¿™é‡Œæˆ‘ä»¬éœ€è¦æ³¨æ„ä½¿ç”¨PriorityQueueçš„ä¸€ä¸ªå‘ç‚¹ï¼Œsame priority ä¸‹ ä¼šå´©æºƒï¼› PriorityQueueæ–‡æ¡£æ²¡å†™ï¼Œheapqå†™äº†
# https://docs.python.org/3/library/heapq.html
class TestNode:
    def __init__(self, point):
        self.point = point


test1 = [
    (-13.30413469565007, 1.2),
    (-9.327379053088816, 0.0),
    (-13.30413469565007, 1.4),
]
test2 = [
    (-13.30413469565007, TestNode(1.2)),
    (-9.327379053088816, TestNode(0.0)),
    (-13.30413469565007, TestNode(1.4)),
]

test3 = [
    (0, TestNode(1.2)),
    (1, TestNode(0.0)),
    (2, TestNode(1.4)),
]

test_pq = PriorityQueue()
for t in test1:
    test_pq.put(t)
print(test_pq.get())
test_pq = PriorityQueue()
for t in test3:
    test_pq.put(t)
print(test_pq.get())
# æ³¨æ„è¿™ç§æƒ…å†µä¸‹æŠ¥é”™
# for t in test2:
#     test_pq.put(t)
# print(test_pq.get())
```

::: {.cell-output .cell-output-stdout}
```
(-13.30413469565007, 1.2)
(0, <__main__.TestNode object>)
```
:::
:::


---

[source](https://github.com/Open-Book-Studio/THU-Coursework-Machine-Learning-for-Big-Data/blob/main/thu_big_data_ml/tree.py#L100){target="_blank" style="float:right; font-size:smaller"}

### knn_classifier

>      knn_classifier (X_train, y_train, X_test, k=3)


---

[source](https://github.com/Open-Book-Studio/THU-Coursework-Machine-Learning-for-Big-Data/blob/main/thu_big_data_ml/tree.py#L35){target="_blank" style="float:right; font-size:smaller"}

### search_kd_tree

>      search_kd_tree (tree, target, k=3)


::: {#cell-21 .cell vscode='{"languageId":"python"}'}
``` {.python .cell-code}
# æ„å»ºKDæ ‘
kd_tree = build_kd_tree(X_train)
```
:::


::: {#cell-22 .cell vscode='{"languageId":"python"}'}
``` {.python .cell-code}
# ä½¿ç”¨KNNç®—æ³•è¿›è¡Œåˆ†ç±»
k_neighbors = 3
y_pred = knn_classifier(X_train, y_train, X_test, k_neighbors)

# è¯„ä¼°åˆ†ç±»æ€§èƒ½
accuracy = accuracy_score(y_test, y_pred)
print(f"KNN Accuracy: {accuracy * 100:.2f}%")
```

::: {.cell-output .cell-output-stdout}
```
KNN Accuracy: 98.61%
```
:::
:::


### è¶…å‚æ•°è°ƒä¼˜

å®éªŒé¢˜ç›®è¦æ±‚æˆ‘ä»¬å¯¹ knn è¿›â¾è¶…å‚æ•°çš„æœç´¢ã€‚é‚£ä¹ˆä»€ä¹ˆæ˜¯è¶…å‚æ•°æœç´¢å‘¢ï¼Ÿä¸ºæ­¤æˆ‘ä»¬éœ€è¦ç†è§£ä¸¤ä¸ªæ¦‚å¿µâ€”â€”è¶…å‚æ•°å’Œæœç´¢ã€‚

#### ä»€ä¹ˆæ˜¯å‚æ•°ï¼Ÿä»€ä¹ˆæ˜¯è¶…å‚æ•°ï¼Ÿä»€ä¹ˆæ˜¯å…ƒå‚æ•°ï¼Ÿ

åœ¨å¤§æ•°æ®åˆ†æä¸­ï¼Œæˆ‘ä»¬å¾€å¾€ä¸çŸ¥é“æ•°æ®çš„æ€»ä½“ï¼Œåªèƒ½è·å¾—æ•°æ®çš„ä¸€ä¸ªé‡‡æ ·ã€‚ç„¶è€Œæˆ‘ä»¬å¯¹æ•°æ®çš„æ€»ä½“æ˜¯ä»€ä¹ˆåˆ†å¸ƒéå¸¸æ„Ÿå…´è¶£ï¼Œè¿™äº›æœªçŸ¥çš„åˆ†å¸ƒï¼Œæˆ‘ä»¬å‡è®¾å¯èƒ½æ˜¯ç”±ä¸€äº›å‚æ•°æ¥å†³å®šçš„ï¼Œæˆ‘ä»¬éœ€è¦æ ¹æ®é‡‡æ ·å‡ºæ¥çš„æ•°æ®å¯¹æ€»ä½“çš„å‚æ•°è¿›è¡Œå‚æ•°ä¼°è®¡ï¼ˆParameter Estimationï¼‰ã€‚æ¯”å¦‚è¯´æ€»ä½“æ˜¯é«˜æ–¯åˆ†å¸ƒï¼Œé‚£ä¹ˆé«˜æ–¯åˆ†å¸ƒçš„å‡å€¼å’Œæ–¹å·®å°±æ˜¯å‚æ•°ã€‚

åˆšæ‰æˆ‘ä»¬è¯´äº†å‚æ•°æ˜¯ä»€ä¹ˆï¼Œé‚£ä¹ˆä»€ä¹ˆæ˜¯è¶…å‚æ•°å‘¢ï¼Ÿå‚æ•°ä¼°è®¡æˆ‘ä»¬é€šå¸¸ä¼šç”¨æå¤§ä¼¼ç„¶ä¼°è®¡æ–¹æ³•ï¼Œä½†æ˜¯ç›¸æ¯”äºè´å¶æ–¯å‚æ•°ä¼°è®¡æ¥è¯´æœ‰ä¸€å®šçš„å±€é™æ€§ã€‚åœ¨è´å¶æ–¯æœºå™¨å­¦ä¹ ä¸­ï¼Œæˆ‘ä»¬è®¤ä¸ºå‚æ•°æœ¬èº«ä¹Ÿæ˜¯æœ‰ä¸€ä¸ªæ¦‚ç‡åˆ†å¸ƒçš„ï¼Œè€Œä¸æ˜¯ç¡®å®šçš„å€¼ï¼Œè€Œæè¿°å‚æ•°åˆ†å¸ƒçš„å‚æ•°ï¼Œæˆ‘ä»¬ç§°ä¹‹ä¸ºè¶…å‚æ•°ã€‚å½“ç„¶ï¼Œæˆ‘ä»¬å¯ä»¥è®¤ä¸ºè¶…å‚æ•°ä¹Ÿæœ‰å…¶åˆ†å¸ƒï¼Œé‚£ä¹ˆå°±æœ‰å¯¹åº”çš„è¶…è¶…å‚æ•°ï¼Œè¿™ç§å¤šå±‚åµŒå¥—çš„ç»“æ„ç§°ä¸ºè´å¶æ–¯ç½‘ç»œã€‚

å¯¹åº”åˆ°æœºå™¨å­¦ä¹ å’Œæ·±åº¦å­¦ä¹ ä¸­ï¼Œå‚æ•°æ˜¯æŒ‡å‚æ•°åŒ–æ¨¡å‹çš„æƒé‡ã€‚ä½†æ˜¯æˆ‘ä»¬æ²¡æœ‰åœ¨ä½¿ç”¨è´å¶æ–¯ä¼°è®¡ï¼Œå¹¶æ²¡æœ‰è¯´è¿™äº›æ¨¡å‹æƒé‡å…·æœ‰ä¸€å®šçš„åˆ†å¸ƒï¼Œé‚£ä¹ˆè¶…å‚æ•°æ˜¯æ€ä¹ˆä¸€å›äº‹å‘¢ï¼Ÿäº‹å®ä¸Šï¼Œæ ¹æ®è°·æ­Œå›¢é˜Ÿæå‡ºçš„ã€Šæ·±åº¦å­¦ä¹ è°ƒä¼˜æŒ‡å—ã€‹[@tuningplaybookgithub]ï¼Œæ·±åº¦å­¦ä¹ ç¤¾åŒºé”™è¯¯åœ°æŠŠå­¦ä¹ ç‡ã€æ‰¹å¤„ç†å¤§å°ã€æ­£åˆ™åŒ–ç³»æ•°ç­‰å‚æ•°å«åšè¶…å‚æ•°ï¼Œè¿™æ˜¯é”™è¯¯çš„ã€‚ä»–ä»¬ç¡®å®å†³å®šäº†æ¨¡å‹çš„å‡è®¾ç©ºé—´çš„ä¸åŒï¼Œå†³å®šäº†æœ€ç»ˆçš„æ€§èƒ½ï¼Œè€Œä¸”åœ¨æ¨¡å‹è®­ç»ƒè¿‡ç¨‹ä¸­ä¸å‘ç”Ÿå˜åŒ–ï¼Œè€Œæ˜¯å†³å®šäº†è®­ç»ƒè¿‡ç¨‹ï¼Œä½†æ˜¯ä»–ä»¬æœ¬èº«å¹¶ä¸æ˜¯å…ˆéªŒåˆ†å¸ƒçš„å‚æ•°ï¼Œä¸¥æ ¼æ¥è¯´ä¸åº”è¯¥å«åšè¶…å‚æ•°ï¼Œåº”è¯¥å«åšå…ƒå‚æ•°ã€‚

#### ä»€ä¹ˆæ˜¯æœç´¢ï¼Ÿ

æœç´¢æ˜¯äººå·¥æ™ºèƒ½ä¸­çš„é‡è¦çš„æ–¹æ³•[@Russell_Norvig_2016]ã€‚æœç´¢åŒ…æ‹¬çº¦æŸå¯æ»¡è¶³é—®é¢˜å’Œæœ€ä¼˜åŒ–é—®é¢˜ï¼Œä»¥åŠå¸¦æœ‰çº¦æŸçš„ä¼˜åŒ–é—®é¢˜ã€‚
è¿™é‡Œæˆ‘ä»¬è¯´çš„è¶…å‚æ•°ä¼˜åŒ–ï¼Œä¸€èˆ¬æ¥è¯´æ˜¯å¸¦æœ‰çº¦æŸçš„ä¼˜åŒ–é—®é¢˜ã€‚
å…¶ä¸­çº¦æŸæ˜¯æŒ‡ï¼Œæœ‰äº›è¶…å‚æ•°ç»„åˆå¦‚æœé”™è¯¯åœ°é€‰æ‹©ï¼Œä¼šå¯¼è‡´æœºå™¨å­¦ä¹ ç³»ç»Ÿå´©æºƒï¼Œæˆ–è€…ç®—æ³•æ— æ³•æ”¶æ•›ã€‚

ç„¶è€Œè¿™äº›çº¦æŸæˆ‘ä»¬å¾ˆå¯èƒ½æ˜¯ä¸çŸ¥é“çš„ï¼Œéœ€è¦è°ƒå‚ç®—æ³•æœ¬èº«å°è¯•ã€‚
æœ‰æ—¶å€™æˆ‘ä»¬å‘ç°çš„çº¦æŸå¯èƒ½æš—ç¤ºç€ä»£ç å­˜åœ¨é”™è¯¯ï¼Œæˆ–è€…æ·±åº¦å­¦ä¹ æ¨¡å‹æœ¬èº«çš„ä¼˜åŒ–è¿‡ç¨‹ä¸å¤Ÿç¨³å®šï¼Œå¦‚æœæ˜¯åè€…ï¼Œå¯ä»¥é€šè¿‡Gradient Clip, é™ä½å­¦ä¹ ç‡ç­‰æ–¹æ³•æ¥ç¼“è§£ã€‚

#### KNNå’ŒKDæ ‘æœ‰å“ªäº›å…ƒå‚æ•°ï¼Ÿ
ä¸Šæ–‡æˆ‘ä»¬è¾¨æäº†KNNå’ŒKDæ ‘çš„å…³ç³»ï¼Œå³æ˜¯å¦é€‰ç”¨KDæ ‘ä½œä¸ºKNNçš„è¿‘é‚»æœç´¢ç®—æ³•ï¼Œæœ¬èº«æ˜¯KNNçš„ä¸€ä¸ªå…ƒå‚æ•°ï¼ŒKNNä¹Ÿå¯ä»¥é€‰æ‹©Ball Treeã€Brute Forceç­‰å…¶ä»–è¿‘é‚»æœç´¢ç®—æ³•ã€‚

KDæ ‘æœ¬èº«ä¹Ÿæœ‰ä¸€äº›å…ƒå‚æ•°ï¼Œæ¯”å¦‚åˆ†å‰²æ–¹å¼ã€èŠ‚ç‚¹çš„é€‰æ‹©æ–¹å¼ç­‰ï¼Œè¿™äº›å…ƒå‚æ•°ä¼šå½±å“KDæ ‘çš„æ„å»ºå’Œæœç´¢çš„ç³»ç»Ÿæ€§èƒ½ï¼ˆæ—¶é—´å¤æ‚åº¦ã€ç©ºé—´å¤æ‚åº¦ï¼‰ï¼Œä½†æ˜¯ä¸ä¼šå½±å“åˆ°æœºå™¨å­¦ä¹ çš„æ€§èƒ½ï¼ˆåˆ†ç±»å‡†ç¡®ç‡ã€ROC-AUCç­‰æŒ‡æ ‡ï¼‰ã€‚å› ä¸ºä¸å½±å“æœºå™¨å­¦ä¹ çš„æ€§èƒ½ï¼Œåœ¨æœ¬èŠ‚æˆ‘ä»¬ä¸è®¨è®ºKDæ ‘çš„å…ƒå‚æ•°å¦‚ä½•è°ƒä¼˜ã€‚æˆ‘ä»¬ä¼šåœ¨ä¸‹ä¸€èŠ‚ï¼Œé™„åŠ é¢˜ä¸­ï¼Œè®¨è®ºä¸åŒçš„KDæ ‘æ„å»ºæ–¹å¼å¯¹æœç´¢é€Ÿåº¦çš„å½±å“ã€‚

é‚£ä¹ˆKNNä½œä¸ºä¸€ä¸ªæœºå™¨å­¦ä¹ ç®—æ³•ï¼Œæœ‰å“ªäº›å…ƒå‚æ•°éœ€è¦è°ƒä¼˜å‘¢ï¼Ÿå‚è€ƒsklearnçš„KNeighborsClassifierç±»çš„å‚æ•°è¯´æ˜ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°ä»¥ä¸‹å‚æ•°

::: {#cell-26 .cell vscode='{"languageId":"python"}'}
``` {.python .cell-code}
# help(KNeighborsClassifier)
# ä½¿ç”¨ ipythonçš„ ? å¯ä»¥æ›´å¥½åœ°çœ‹åˆ° å‡½æ•°å’Œç±»çš„docstringä¿¡æ¯ã€‚
KNeighborsClassifier?
```

::: {.cell-output .cell-output-stdout}
```````
Init signature:
KNeighborsClassifier(
    n_neighbors=5,
    *,
    weights='uniform',
    algorithm='auto',
    leaf_size=30,
    p=2,
    metric='minkowski',
    metric_params=None,
    n_jobs=None,
)
Docstring:     
Classifier implementing the k-nearest neighbors vote.

Read more in the :ref:`User Guide <classification>`.

Parameters
----------
n_neighbors : int, default=5
    Number of neighbors to use by default for :meth:`kneighbors` queries.

weights : {'uniform', 'distance'}, callable or None, default='uniform'
    Weight function used in prediction.  Possible values:

    - 'uniform' : uniform weights.  All points in each neighborhood
      are weighted equally.
    - 'distance' : weight points by the inverse of their distance.
      in this case, closer neighbors of a query point will have a
      greater influence than neighbors which are further away.
    - [callable] : a user-defined function which accepts an
      array of distances, and returns an array of the same shape
      containing the weights.

    Refer to the example entitled
    :ref:`sphx_glr_auto_examples_neighbors_plot_classification.py`
    showing the impact of the `weights` parameter on the decision
    boundary.

algorithm : {'auto', 'ball_tree', 'kd_tree', 'brute'}, default='auto'
    Algorithm used to compute the nearest neighbors:

    - 'ball_tree' will use :class:`BallTree`
    - 'kd_tree' will use :class:`KDTree`
    - 'brute' will use a brute-force search.
    - 'auto' will attempt to decide the most appropriate algorithm
      based on the values passed to :meth:`fit` method.

    Note: fitting on sparse input will override the setting of
    this parameter, using brute force.

leaf_size : int, default=30
    Leaf size passed to BallTree or KDTree.  This can affect the
    speed of the construction and query, as well as the memory
    required to store the tree.  The optimal value depends on the
    nature of the problem.

p : float, default=2
    Power parameter for the Minkowski metric. When p = 1, this is equivalent
    to using manhattan_distance (l1), and euclidean_distance (l2) for p = 2.
    For arbitrary p, minkowski_distance (l_p) is used. This parameter is expected
    to be positive.

metric : str or callable, default='minkowski'
    Metric to use for distance computation. Default is "minkowski", which
    results in the standard Euclidean distance when p = 2. See the
    documentation of `scipy.spatial.distance
    <https://docs.scipy.org/doc/scipy/reference/spatial.distance.html>`_ and
    the metrics listed in
    :class:`~sklearn.metrics.pairwise.distance_metrics` for valid metric
    values.

    If metric is "precomputed", X is assumed to be a distance matrix and
    must be square during fit. X may be a :term:`sparse graph`, in which
    case only "nonzero" elements may be considered neighbors.

    If metric is a callable function, it takes two arrays representing 1D
    vectors as inputs and must return one value indicating the distance
    between those vectors. This works for Scipy's metrics, but is less
    efficient than passing the metric name as a string.

metric_params : dict, default=None
    Additional keyword arguments for the metric function.

n_jobs : int, default=None
    The number of parallel jobs to run for neighbors search.
    ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.
    ``-1`` means using all processors. See :term:`Glossary <n_jobs>`
    for more details.
    Doesn't affect :meth:`fit` method.

Attributes
----------
classes_ : array of shape (n_classes,)
    Class labels known to the classifier

effective_metric_ : str or callble
    The distance metric used. It will be same as the `metric` parameter
    or a synonym of it, e.g. 'euclidean' if the `metric` parameter set to
    'minkowski' and `p` parameter set to 2.

effective_metric_params_ : dict
    Additional keyword arguments for the metric function. For most metrics
    will be same with `metric_params` parameter, but may also contain the
    `p` parameter value if the `effective_metric_` attribute is set to
    'minkowski'.

n_features_in_ : int
    Number of features seen during :term:`fit`.

    .. versionadded:: 0.24

feature_names_in_ : ndarray of shape (`n_features_in_`,)
    Names of features seen during :term:`fit`. Defined only when `X`
    has feature names that are all strings.

    .. versionadded:: 1.0

n_samples_fit_ : int
    Number of samples in the fitted data.

outputs_2d_ : bool
    False when `y`'s shape is (n_samples, ) or (n_samples, 1) during fit
    otherwise True.

See Also
--------
RadiusNeighborsClassifier: Classifier based on neighbors within a fixed radius.
KNeighborsRegressor: Regression based on k-nearest neighbors.
RadiusNeighborsRegressor: Regression based on neighbors within a fixed radius.
NearestNeighbors: Unsupervised learner for implementing neighbor searches.

Notes
-----
See :ref:`Nearest Neighbors <neighbors>` in the online documentation
for a discussion of the choice of ``algorithm`` and ``leaf_size``.

.. warning::

   Regarding the Nearest Neighbors algorithms, if it is found that two
   neighbors, neighbor `k+1` and `k`, have identical distances
   but different labels, the results will depend on the ordering of the
   training data.

https://en.wikipedia.org/wiki/K-nearest_neighbor_algorithm

Examples
--------
>>> X = [[0], [1], [2], [3]]
>>> y = [0, 0, 1, 1]
>>> from sklearn.neighbors import KNeighborsClassifier
>>> neigh = KNeighborsClassifier(n_neighbors=3)
>>> neigh.fit(X, y)
KNeighborsClassifier(...)
>>> print(neigh.predict([[1.1]]))
[0]
>>> print(neigh.predict_proba([[0.9]]))
[[0.666... 0.333...]]
File:           ~/program_files/managers/conda/envs/hf_ai/lib/python3.10/site-packages/sklearn/neighbors/_classification.py
Type:           ABCMeta
Subclasses:     
```````
:::
:::


å…¶ä¸­è¿™å‡ ä¸ªå‚æ•°æ˜¯å’Œåˆ†ç±»å‡†ç¡®ç‡æœ‰å…³çš„
- `n_neighbors`, ä¹Ÿå°±æ˜¯k
- `weights`ï¼Œæ£€ç´¢å‡ºæ¥çš„kä¸ªç‚¹ç”¨æ¥å†³ç­–ï¼Œè¿™äº›ç‚¹ä¸€æ ·é‡è¦å—ï¼Ÿ
  - æˆ‘ä»¬æèˆªä¹¦å­¦çš„åŸºç¡€ç‰ˆæœ¬æ˜¯uniformï¼Œè€Œdistanceæ–¹æ³•ä¸ä¸€æ ·åœ¨äº
  - æ¯ä¸€ä¸ªç‚¹çš„æŠ•ç¥¨æƒæ˜¯è·ç¦»çš„-1æ¬¡æ–¹ã€‚ï¼ˆå“ˆå“ˆä¸ºä»€ä¹ˆä¸æ˜¯åƒä¸‡æœ‰å¼•åŠ›é‚£æ ·æ˜¯-2æ¬¡æ–¹ï¼‰
- `p`å’Œ`metric`å’Œ`metric_params`, è¦æ€ä¹ˆè®¡ç®—è·ç¦»ï¼Ÿ

è€Œ `algorithm` `leaf_size` `n_jobs` ä¸‰ä¸ªå‚æ•°æš‚æ—¶å’Œæˆ‘ä»¬æ— å…³ã€‚

::: {#cell-28 .cell vscode='{"languageId":"python"}' execution_count=9}
``` {.python .cell-code}
from sklearn.metrics.pairwise import distance_metrics
distance_metrics().keys()
```

::: {.cell-output .cell-output-display execution_count=9}
```
dict_keys(['cityblock', 'cosine', 'euclidean', 'haversine', 'l2', 'l1', 'manhattan', 'precomputed', 'nan_euclidean'])
```
:::
:::


#### å…·ä½“è¦æ€ä¹ˆè°ƒå‚å‘¢ï¼Ÿ

å¦‚æœæˆ‘ä»¬å°±æŠŠè°ƒå‚é—®é¢˜å½“åšæœç´¢é—®é¢˜ï¼Œé‚£ä¹ˆå®ƒå°±æ˜¯ä¸€ä¸ªæ— æ¢¯åº¦é»‘ç›’æœ€ä¼˜åŒ–é—®é¢˜ã€‚å¯¹äºè¿™ç±»é—®é¢˜ï¼Œæœ€å¹³å‡¡ï¼ˆtrivialï¼‰çš„æœç´¢æ–¹æ³•æ˜¯å…¨ç›˜éå†ï¼ˆgrid searchï¼‰ï¼Œç„¶è€Œå½“æœç´¢ç©ºé—´å¤ªå¤§çš„æ—¶å€™ï¼Œè¿™å°±ä¸æ˜¯å¾ˆé«˜æ•ˆäº†ã€‚ä¸€äº›åŸºç¡€çš„æ”¹è¿›æ˜¯è´ªå¿ƒç®—æ³•å’ŒéšæœºåŒ–æœç´¢æ–¹æ³•ï¼Œæ¯”å¦‚çˆ¬å±±æ³•ã€éšæœºé‡‡æ ·æ³•ã€æ¨¡æ‹Ÿé€€ç«æ³•ç­‰[@Russell_Norvig_2016]ã€‚è€Œè¦æƒ³å¾—åˆ°æœ€å…ˆè¿›ï¼ˆSOTAï¼‰çš„æ€§èƒ½ï¼Œæ¼”åŒ–è®¡ç®—å’Œè´å¶æ–¯ä¼˜åŒ–æ˜¯ä¸¤ä¸ªæœ€å¥½çš„æ–¹æ³•ï¼Œä¹Ÿæ˜¯ç›®å‰äººå·¥æ™ºèƒ½ä»ç„¶æ´»è·ƒçš„ç§‘ç ”æ–¹å‘[@Russell_Norvig_2016]ã€‚

ç„¶è€Œè°ƒå‚é—®é¢˜å¹¶ä¸å®Œå…¨æ˜¯æœç´¢é—®é¢˜ã€‚Googleçš„ã€Šæ·±åº¦å­¦ä¹ è°ƒä¼˜æŒ‡å—ã€‹[@tuningplaybookgithub]æŒ‡å‡ºï¼Œè°ƒå‚æ˜¯ä¸€ä¸ªâ€œæ¢ç´¢ä¸åˆ©ç”¨â€ï¼ˆexploration and exploitationï¼‰çš„è¿‡ç¨‹ã€‚æˆ‘çš„ç†è§£æ˜¯ï¼Œåœ¨æˆ‘ä»¬åšæ·±åº¦å­¦ä¹ ç ”ç©¶çš„æ—¶å€™ï¼Œæˆ‘ä»¬å…¶å®æ›´æƒ³çŸ¥é“ï¼Œæˆ‘ä»¬çš„æ–¹æ³•å¯¹äºé‚£äº›è¶…å‚æ•°æ•æ„Ÿï¼Œåœ¨å…¶ä»–æ–¹æ³•ä¹Ÿè°ƒåˆ°æœ€ä¼˜è¶…å‚çš„æƒ…å†µä¸‹æˆ‘çš„æ–¹æ³•æ˜¯å¦ä»ç„¶æ˜¾è‘—ä¼˜äºå…¶ä»–æ–¹æ³•ï¼Œè€Œä¸åªæ˜¯è¯´æˆ‘çš„æ–¹æ³•åœ¨å•å•ä¸€ä¸ªè¶…å‚æ•°ä¸Šä¼˜äºå…¶ä»–æ–¹æ³•ï¼ˆé€‰æ‹©â€œæˆ‘çš„æ–¹æ³•â€è¿˜æ˜¯â€œå…¶ä»–è¿‘æœŸSOTAæ–¹æ³•â€å°±æ˜¯ä¸€ä¸ªç¦»æ•£å‹ç›®æ ‡å…ƒå‚æ•°ï¼‰ã€‚å› æ­¤ï¼Œæˆ‘ä»¬éœ€è¦åœ¨è°ƒå‚çš„è¿‡ç¨‹ä¸­ç†è§£ä¸åŒçš„å‚æ•°å¯¹äºç»“æœçš„å½±å“ã€‚è¿™å…¶å®ä¹Ÿæ˜¯ä½œä¸ºç§‘å­¦å®¶å’Œç ”ç©¶è€…æˆ‘ä»¬åšç§‘å­¦å®éªŒçš„è¿‡ç¨‹ã€‚è°ƒå‚çš„å®è´¨ä¸æ˜¯ä¹±è¯•ï¼Œè€Œæ˜¯â€œæ§åˆ¶å˜é‡â€ï¼Œå‚æ•°å°±æ˜¯è‡ªå˜é‡å’Œæ— å…³å˜é‡ï¼Œè¯„ä»·æŒ‡æ ‡å°±æ˜¯å› å˜é‡ã€‚ä¸è¿‡ï¼Œä¸æˆ‘ä»¬é«˜ä¸­ç”Ÿç‰©è¯¾å­¦ä¹ çš„â€œæ§åˆ¶å˜é‡æ³•â€ç¨æœ‰ä¸åŒï¼Œæ— å…³å˜é‡ä¸ä¸€å®šæ˜¯æ§åˆ¶ç›¸ç­‰ï¼Œåœ¨è®¡ç®—èµ„æºå……è¶³æ—¶ï¼Œæ— å…³å˜é‡åº”è¯¥æ§åˆ¶åˆ°æœ€ä¼˜ï¼Œæ‰€ä»¥è¿™é‡Œæœ‰ä¼˜åŒ–é—®é¢˜ã€‚

å¯¹äºå…·ä½“çš„è°ƒå‚ç®—æ³•å’Œä»£ç è€Œè¨€ï¼Œæˆ‘ä»¬å½“ç„¶å¯ä»¥ç”¨sklearné»˜è®¤æä¾›çš„GridSearchCVã€RandomizedSearchCVç­‰æ–¹æ³•ï¼Œæˆ‘çŒœåšè¿™ä¸ªä½œä¸šçš„å¤§éƒ¨åˆ†åŒå­¦ç”¨çš„æ˜¯è¿™ä¸¤ä¸ªã€‚ä½†æ˜¯åˆšæ‰æˆ‘ä»¬ä¹Ÿè¯´äº†ï¼ŒGridSearchä»£ä»·å¤ªé«˜ï¼Œè€ŒRandomizedSearchCVä»¥åŠè´å¶æ–¯ä¼˜åŒ–ã€æ¼”åŒ–è®¡ç®—å¿™äºâ€œåˆ©ç”¨â€ï¼Œè€Œæ²¡æœ‰è¿›è¡Œå•ä¸€å˜é‡åŸåˆ™ï¼Œæ— æ³•é€šè¿‡ç§‘å­¦å®éªŒâ€œæ¢ç´¢â€å‡ºæˆ‘ä»¬æƒ³è·å¾—çš„insightã€‚æ ¹æ®Googleçš„å»ºè®®ï¼Œåœ¨æ¢ç´¢é˜¶æ®µæœ€é€‚åˆçš„ç®—æ³•å…¶å®æ˜¯å‡†éšæœºæœç´¢ç®—æ³•ï¼ˆquasi random searchï¼‰ã€‚

å› æ­¤ï¼Œæˆ‘ä»¬éµå¾ªgoogleæŒ‡å—ï¼Œä½¿ç”¨Optuna+Ray Tuneä¸­çš„Quasi Random Searchå®ç°æ¥è¿›è¡Œè°ƒå‚ã€‚


æ­¤å¤–ï¼Œæˆ‘è¿˜å®ç°äº†ä¸€ä¸ªâ€œå­¦ç”Ÿå®éªŒç®—æ³•â€ï¼Œè¿™ä¸ªç®—æ³•ä»ä¼˜åŒ–ä¸Šæ¥è¯´æ˜¯ä¸€ç§äº¤æ›¿ä¼˜åŒ–ï¼ˆalternating optimizationï¼‰æˆ–è€…å«åšå¤šé˜¶æ®µä¼˜åŒ–ï¼ˆmulti-stage optimizationï¼‰çš„æ–¹æ³•ï¼Œå³å…ˆå›ºå®šä¸€ä¸ªè¶…å‚æ•°ï¼Œç„¶ååœ¨è¿™ä¸ªè¶…å‚æ•°ä¸‹è¿›è¡Œä¼˜åŒ–ï¼Œå†å›ºå®šå¦ä¸€ä¸ªè¶…å‚æ•°ï¼Œå†è¿›è¡Œä¼˜åŒ–ï¼Œä»¥æ­¤ç±»æ¨ï¼Œç›´åˆ°æ‰€æœ‰è¶…å‚æ•°éƒ½ä¼˜åŒ–å®Œæ¯•ã€‚è¿™ä¸ªç®—æ³•çš„å¥½å¤„æ˜¯éµå¾ªäº†å•ä¸€å˜é‡åŸåˆ™å’Œæ— å…³å˜é‡æ§åˆ¶ç›¸ç­‰åŸåˆ™ï¼Œå¯ä»¥æ¢ç´¢å‡ºå¾ˆå¤šç»“è®ºã€‚æˆ‘æŠŠè¿™ä¸ªç®—æ³•å†™æˆäº†ä¸€ä¸ªpypiåº“ï¼Œå¯è§[githubè¿æ¥](https://github.com/2catycm/CosmicSelection.git)ã€‚


åœ¨è¿™é‡Œæˆ‘ä»¬ä¹Ÿåšä¸€ä¸ªç§‘å­¦å®éªŒï¼Œå®éªŒå‡è®¾æ˜¯åœ¨å…¶ä»–å‚æ•°æœ€ä¼˜æ—¶ï¼Œä½¿ç”¨"distance"çš„KNNæ¯”æ™®é€šçš„"uniform"KNNçš„æ•ˆæœå¥½ã€‚
è¿™æ ·æˆ‘ä»¬æœ‰ä¸€ä¸ªç ”ç©¶çš„ç›®æ ‡ï¼Œç›¸å½“äºæˆ‘ä»¬æ‰®æ¼”é‚£ä¸ªæå‡º"distance"æ–¹æ³•çš„ç§‘å­¦å®¶ï¼Œè¦å’Œå…¶ä»–äººçš„æ–¹æ³•åšæ¯”è¾ƒæ‰èƒ½å‘è®ºæ–‡ã€‚

#### ä»£ç å®ç°è°ƒä¼˜

é¦–å…ˆæˆ‘ä»¬éœ€è¦å®šä¹‰KNNå…ƒå‚æ•°çš„åˆ†å¸ƒç©ºé—´

ç„¶åæˆ‘ä»¬å®šä¹‰è¯„ä»·å‡½æ•°

---

[source](https://github.com/Open-Book-Studio/THU-Coursework-Machine-Learning-for-Big-Data/blob/main/thu_big_data_ml/tree.py#L128){target="_blank" style="float:right; font-size:smaller"}

### evaluate_knn

>      evaluate_knn (weights:str, n_neighbors:int, distance_metric:str,
>                    random_seed:int=42)


---

[source](https://github.com/Open-Book-Studio/THU-Coursework-Machine-Learning-for-Big-Data/blob/main/thu_big_data_ml/tree.py#L161){target="_blank" style="float:right; font-size:smaller"}

### objective

>      objective (meta_parameters)


æ¥ä¸‹æ¥æˆ‘ä»¬è¦å®šä¹‰ä½¿ç”¨çš„æœç´¢ç®—æ³•ã€‚

::: {#cell-35 .cell vscode='{"languageId":"python"}'}
``` {.python .cell-code}
from ray.tune.search import ConcurrencyLimiter
from ray.tune.search.optuna import OptunaSearch
from optuna.samplers import QMCSampler
# quasi random search
sampler = QMCSampler()
algo = OptunaSearch(sampler=sampler)
algo = ConcurrencyLimiter(algo, max_concurrent=4)
```

::: {.cell-output .cell-output-stderr}
```
ExperimentalWarning: QMCSampler is experimental (supported from v3.0.0). The interface can change in the future.
  sampler = QMCSampler()
```
:::
:::


```python
tuner = tune.Tuner(
    objective,
    tune_config=tune.TuneConfig(
        metric="mean_score",
        mode="max",
        num_samples=100,
        # num_samples=3,
        search_alg=algo,
    ),
    param_space=search_space,
)
results:tune.ResultGrid  = tuner.fit()
```

::: {#cell-37 .cell vscode='{"languageId":"python"}'}
``` {.python .cell-code}
experiment_dir = "/home/ycm/ray_results/objective_2024-10-22_23-27-35"
# https://docs.ray.io/en/latest/tune/examples/tune_analyze_results.html
restored_tuner = tune.Tuner.restore(experiment_dir, objective)
results = restored_tuner.get_results()
```
:::


::: {#cell-38 .cell vscode='{"languageId":"python"}'}
``` {.python .cell-code}
results.errors
```

::: {.cell-output .cell-output-display}
```
[]
```
:::
:::


#### è°ƒä¼˜ç»“æœåˆ†æ

::: {#cell-40 .cell vscode='{"languageId":"python"}'}
``` {.python .cell-code}
from ray.train import Result
best_result:Result = results.get_best_result()
{k:v for k,v in best_result.metrics.items() if "score" in k}, best_result.config
```

::: {.cell-output .cell-output-display}
```
({'mean_score': 0.9860796554394116,
  'std_score': 0.003124647521844644,
  'score_0': 0.9861111111111112,
  'score_1': 0.9895833333333334,
  'score_2': 0.9825783972125436,
  'score_3': 0.9825783972125436,
  'score_4': 0.9895470383275261},
 {'weights': 'distance', 'n_neighbors': 1, 'distance_metric': 'euclidean'})
```
:::
:::


::: {#cell-41 .cell vscode='{"languageId":"python"}'}
``` {.python .cell-code}
df = results.get_dataframe(
    filter_metric="mean_score", filter_mode="max"
)
df.head()
```

::: {.cell-output .cell-output-display}

```{=html}
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>mean_score</th>
      <th>std_score</th>
      <th>score_0</th>
      <th>score_1</th>
      <th>score_2</th>
      <th>score_3</th>
      <th>score_4</th>
      <th>timestamp</th>
      <th>checkpoint_dir_name</th>
      <th>done</th>
      <th>...</th>
      <th>time_total_s</th>
      <th>pid</th>
      <th>hostname</th>
      <th>node_ip</th>
      <th>time_since_restore</th>
      <th>iterations_since_restore</th>
      <th>config/weights</th>
      <th>config/n_neighbors</th>
      <th>config/distance_metric</th>
      <th>logdir</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.978421</td>
      <td>0.008356</td>
      <td>0.972222</td>
      <td>0.993056</td>
      <td>0.972125</td>
      <td>0.972125</td>
      <td>0.982578</td>
      <td>1729610862</td>
      <td>None</td>
      <td>False</td>
      <td>...</td>
      <td>0.142350</td>
      <td>302368</td>
      <td>amax</td>
      <td>10.103.10.61</td>
      <td>0.142350</td>
      <td>1</td>
      <td>uniform</td>
      <td>8</td>
      <td>l2</td>
      <td>9db3a177</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.972854</td>
      <td>0.006012</td>
      <td>0.972222</td>
      <td>0.982639</td>
      <td>0.965157</td>
      <td>0.968641</td>
      <td>0.975610</td>
      <td>1729610871</td>
      <td>None</td>
      <td>False</td>
      <td>...</td>
      <td>0.249111</td>
      <td>303174</td>
      <td>amax</td>
      <td>10.103.10.61</td>
      <td>0.249111</td>
      <td>1</td>
      <td>uniform</td>
      <td>15</td>
      <td>nan_euclidean</td>
      <td>ad504238</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.978424</td>
      <td>0.007435</td>
      <td>0.972222</td>
      <td>0.989583</td>
      <td>0.968641</td>
      <td>0.982578</td>
      <td>0.979094</td>
      <td>1729610864</td>
      <td>None</td>
      <td>False</td>
      <td>...</td>
      <td>0.072539</td>
      <td>302745</td>
      <td>amax</td>
      <td>10.103.10.61</td>
      <td>0.072539</td>
      <td>1</td>
      <td>distance</td>
      <td>17</td>
      <td>cosine</td>
      <td>c0464454</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.986080</td>
      <td>0.003125</td>
      <td>0.986111</td>
      <td>0.989583</td>
      <td>0.982578</td>
      <td>0.982578</td>
      <td>0.989547</td>
      <td>1729610866</td>
      <td>None</td>
      <td>False</td>
      <td>...</td>
      <td>0.051633</td>
      <td>302934</td>
      <td>amax</td>
      <td>10.103.10.61</td>
      <td>0.051633</td>
      <td>1</td>
      <td>distance</td>
      <td>1</td>
      <td>euclidean</td>
      <td>5cc5dc31</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.974937</td>
      <td>0.009465</td>
      <td>0.975694</td>
      <td>0.989583</td>
      <td>0.961672</td>
      <td>0.968641</td>
      <td>0.979094</td>
      <td>1729610869</td>
      <td>None</td>
      <td>False</td>
      <td>...</td>
      <td>0.401711</td>
      <td>303051</td>
      <td>amax</td>
      <td>10.103.10.61</td>
      <td>0.401711</td>
      <td>1</td>
      <td>uniform</td>
      <td>10</td>
      <td>nan_euclidean</td>
      <td>8bd53b66</td>
    </tr>
  </tbody>
</table>
<p>5 rows Ã— 24 columns</p>
</div>
```

:::
:::


::: {#cell-42 .cell vscode='{"languageId":"python"}'}
``` {.python .cell-code}
intersted_cols = [c for c in df.columns if c.startswith("config") or "score" in c]
dfi = df[intersted_cols]
dfi.head()
```

::: {.cell-output .cell-output-display}

```{=html}
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>mean_score</th>
      <th>std_score</th>
      <th>score_0</th>
      <th>score_1</th>
      <th>score_2</th>
      <th>score_3</th>
      <th>score_4</th>
      <th>config/weights</th>
      <th>config/n_neighbors</th>
      <th>config/distance_metric</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.978421</td>
      <td>0.008356</td>
      <td>0.972222</td>
      <td>0.993056</td>
      <td>0.972125</td>
      <td>0.972125</td>
      <td>0.982578</td>
      <td>uniform</td>
      <td>8</td>
      <td>l2</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.972854</td>
      <td>0.006012</td>
      <td>0.972222</td>
      <td>0.982639</td>
      <td>0.965157</td>
      <td>0.968641</td>
      <td>0.975610</td>
      <td>uniform</td>
      <td>15</td>
      <td>nan_euclidean</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.978424</td>
      <td>0.007435</td>
      <td>0.972222</td>
      <td>0.989583</td>
      <td>0.968641</td>
      <td>0.982578</td>
      <td>0.979094</td>
      <td>distance</td>
      <td>17</td>
      <td>cosine</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.986080</td>
      <td>0.003125</td>
      <td>0.986111</td>
      <td>0.989583</td>
      <td>0.982578</td>
      <td>0.982578</td>
      <td>0.989547</td>
      <td>distance</td>
      <td>1</td>
      <td>euclidean</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.974937</td>
      <td>0.009465</td>
      <td>0.975694</td>
      <td>0.989583</td>
      <td>0.961672</td>
      <td>0.968641</td>
      <td>0.979094</td>
      <td>uniform</td>
      <td>10</td>
      <td>nan_euclidean</td>
    </tr>
  </tbody>
</table>
</div>
```

:::
:::


é¦–å…ˆæˆ‘ä»¬ä»æ•´ä½“ä¸Šæ¥çœ‹ä¸¤ä¸ªæ–¹æ³•ï¼ˆdistanceå’Œuniformï¼‰çš„æ€§èƒ½å·®å¼‚ã€‚

::: {#cell-44 .cell vscode='{"languageId":"python"}'}
``` {.python .cell-code}
import matplotlib.pyplot as plt
import seaborn as sns
```
:::


::: {#cell-45 .cell vscode='{"languageId":"python"}'}
``` {.python .cell-code}
fig, ax = plt.subplots()
sns.boxplot(data=dfi, x='config/weights', y='mean_score', ax=ax)
dfi.plot(x='config/weights', y='mean_score', ax=ax, kind='scatter', c='red')
```

::: {.cell-output .cell-output-display}
![uniformä¸distanceæ–¹æ³•å¹³å‡å‡†ç¡®ç‡ç®±çº¿å›¾å¯¹æ¯”](kd_tree_files/figure-html/cell-25-output-1.png){fig-alt='æ¯ä¸€ä¸ªçº¢ç‚¹æ˜¯ä¸€æ¬¡å®éªŒç»“æœï¼Œå¹³å‡å‡†ç¡®ç‡æ˜¯æ¯ä¸€æ¬¡å®éªŒä¸­äº”æŠ˜äº¤å‰éªŒè¯çš„å¹³å‡å€¼ã€‚'}
:::
:::


ä»¥ä¸Šçš„ç»“æœå¹¶æ²¡æœ‰æ§åˆ¶å˜é‡ï¼Œæ˜¯ç›´æ¥è¿›è¡Œäº†ä¸€ä¸ªç»Ÿè®¡ã€‚ç›¸å…³æ€§ä¸ä»£è¡¨å› æœæ€§ï¼Œæ‰€ä»¥ä¸Šé¢çš„ç»“æœä»…ä»…ä»£è¡¨äº†åœ¨æˆ‘ä»¬è°ƒå‚é‡‡æ ·è¿‡ç¨‹ä¸­ï¼Œè‡ªå˜é‡â€œweightsâ€ä¸å› å˜é‡â€œmean_scoreâ€çš„ä¸€å®šçš„ç›¸å…³æ€§ã€‚
å¦‚æœæˆ‘ä»¬ä¸çŸ¥é“æ¯ä¸€æ¬¡å®éªŒå…·ä½“çš„å…¶ä»–çš„æ— å…³å˜é‡ï¼Œä¸Šé¢çš„å›¾æˆ‘ä»¬ä¹Ÿå¯ä»¥åšä¸€ä¸ªåˆç†çš„å‡è®¾æ£€éªŒï¼ˆéªŒè¯æˆ‘ä»¬çš„å®éªŒå‡è®¾çš„é›¶å‡è®¾æ˜¯å¦è¦æ‹’ç»ï¼ï¼‰ã€‚

æ ¹æ®è®ºæ–‡[@DemÅ¡ar_2006]ï¼Œåœ¨æœºå™¨å­¦ä¹ ä¸­åº”è¯¥ä½¿ç”¨mann-whitney Uæ£€éªŒå’ŒWilcoxon signed-rankæ£€éªŒï¼Œå› ä¸ºè¿™ä¸¤ä¸ªæ£€éªŒå¯¹æ ·æœ¬çš„åˆ†å¸ƒæ²¡æœ‰å‡å®šï¼Œè€Œå…¶ä»–çš„ä¸€äº›æ£€éªŒæ¯”å¦‚tæ£€éªŒä¸å¤ªé€‚ç”¨ä¸æ ·æœ¬åˆ†å¸ƒä¸ç¬¦åˆå‡è®¾åˆ†å¸ƒçš„æƒ…å†µã€‚å…¶ä¸­å¯¹äº â€œä¸çŸ¥é“æ¯ä¸€æ¬¡å®éªŒçš„å…¶ä»–æ— å…³å˜é‡æ˜¯ä»€ä¹ˆâ€çš„æƒ…å†µï¼Œä¹Ÿå°±æ˜¯è¯´è‡ªå˜é‡å–â€œdistanceâ€å’Œâ€œuniformâ€å¾—åˆ°çš„ä¸¤åˆ—æ ·æœ¬æ˜¯ç‹¬ç«‹ï¼ˆindependentï¼‰çš„æ—¶å€™ï¼Œåº”å½“ä½¿ç”¨mann-whitney Uæ£€éªŒã€‚

::: {#cell-47 .cell vscode='{"languageId":"python"}'}
``` {.python .cell-code}
from scipy.stats import mannwhitneyu
```
:::


::: {#cell-48 .cell vscode='{"languageId":"python"}'}
``` {.python .cell-code}
grouped = dfi.groupby('config/weights')
group_mean_scores = {name:group['mean_score'] for name, group in grouped}
scores_for_distance = group_mean_scores['distance']
scores_for_uniform = group_mean_scores['uniform']
u, p = mannwhitneyu(scores_for_distance, scores_for_uniform, 
                    alternative='greater' # å®éªŒå¤‡åˆ™å‡è®¾ï¼Œdistance æ–¹æ³•æ›´å¥½
                    )
if p < 0.05:
    print("Reject null hypothesis! `distance` is significantly better than `uniform`")
```

::: {.cell-output .cell-output-stdout}
```
Reject null hypothesis! `distance` is significantly better than `uniform`
```
:::
:::


åˆšæ‰æˆ‘ä»¬åªæ˜¯æ•´ä½“åˆ†æã€‚
æ¥ä¸‹æ¥æˆ‘ä»¬è¦å¯»æ‰¾æ§åˆ¶å…¶ä»–å˜é‡æœ€ä¼˜æ—¶ï¼Œä¸¤ä¸ªæ–¹æ³•å„è‡ªæœ€ä¼˜çš„å‚æ•°æ˜¯ä»€ä¹ˆï¼Ÿä»¥åŠè¿™ä¸¤ä¸ªæ–¹æ³•å¯¹å“ªäº›è¶…å‚æ•°æ¯”è¾ƒæ•æ„Ÿï¼Ÿ

æˆ‘ä»¬å…ˆå›ç­”ç¬¬ä¸€ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬ä»åˆšæ‰çš„è¡¨æ ¼ç­›é€‰ä¸€ä¸‹ã€‚

::: {#cell-50 .cell vscode='{"languageId":"python"}'}
``` {.python .cell-code}
max_rows = dfi.loc[df.groupby('config/weights')['mean_score'].idxmax()]
max_rows
```

::: {.cell-output .cell-output-display}

```{=html}
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>mean_score</th>
      <th>std_score</th>
      <th>score_0</th>
      <th>score_1</th>
      <th>score_2</th>
      <th>score_3</th>
      <th>score_4</th>
      <th>config/weights</th>
      <th>config/n_neighbors</th>
      <th>config/distance_metric</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>3</th>
      <td>0.98608</td>
      <td>0.003125</td>
      <td>0.986111</td>
      <td>0.989583</td>
      <td>0.982578</td>
      <td>0.982578</td>
      <td>0.989547</td>
      <td>distance</td>
      <td>1</td>
      <td>euclidean</td>
    </tr>
    <tr>
      <th>36</th>
      <td>0.98608</td>
      <td>0.003125</td>
      <td>0.986111</td>
      <td>0.989583</td>
      <td>0.982578</td>
      <td>0.982578</td>
      <td>0.989547</td>
      <td>uniform</td>
      <td>1</td>
      <td>l2</td>
    </tr>
  </tbody>
</table>
</div>
```

:::
:::


è¿™é‡Œæˆ‘ä»¬å¯ä»¥å¯¹5æ¬¡å®éªŒçš„ç»“æœè¿›è¡Œç»Ÿè®¡åˆ†æï¼Œç”±äºè¿™äº”æ¬¡å®éªŒæ˜¯ç›¸å…³çš„ï¼Œå³è¿™äº”æ¬¡å®éªŒæ¯ä¸€æ¬¡ç”¨çš„åŒä¸€ä¸ªfoldå»è®­ç»ƒï¼Œæ‰€ä»¥è¿™é‡Œæˆ‘ä»¬ä¸åº”å½“ç”¨mann-whitney Uæ£€éªŒï¼Œè¿™ä¸€æ¬¡æˆ‘ä»¬è¦ç”¨Wilcoxon signed-rankæ£€éªŒã€‚

::: {#cell-52 .cell vscode='{"languageId":"python"}'}
``` {.python .cell-code}
from scipy.stats import wilcoxon
```
:::


::: {#cell-53 .cell vscode='{"languageId":"python"}'}
``` {.python .cell-code}
scores_for_distance = [v for k, v in max_rows.iloc[0].to_dict().items() if k.startswith('score_')]
scores_for_uniform = [v for k, v in max_rows.iloc[1].to_dict().items() if k.startswith('score_')]
u, p = wilcoxon(scores_for_distance, scores_for_uniform, 
                zero_method='zsplit',
                    alternative='greater' # å®éªŒå¤‡åˆ™å‡è®¾ï¼Œdistance æ–¹æ³•æ›´å¥½
                    )
if p> 0.05:
    print("Null hypothesis cannot be rejected, so I have to accept it. ")
```

::: {.cell-output .cell-output-stdout}
```
Null hypothesis cannot be rejected, so I have to accept it. 
```
:::

::: {.cell-output .cell-output-stderr}
```
/home/ycm/program_files/managers/conda/envs/hf_ai/lib/python3.10/site-packages/scipy/stats/_axis_nan_policy.py:531: UserWarning: Exact p-value calculation does not work if there are zeros. Switching to normal approximation.
  res = hypotest_fun_out(*samples, **kwds)
/home/ycm/program_files/managers/conda/envs/hf_ai/lib/python3.10/site-packages/scipy/stats/_axis_nan_policy.py:531: UserWarning: Sample size too small for normal approximation.
  res = hypotest_fun_out(*samples, **kwds)
```
:::
:::


åŸæ¥ï¼Œå½“æˆ‘ä»¬æ§åˆ¶æ— å…³å˜é‡æœ€ä¼˜æ—¶ï¼Œä¸¤ä¸ªæ–¹æ³•çš„æ€§èƒ½èƒ½è¾¾åˆ°ä¸€è‡´ã€‚å…·ä½“æ¥è¯´ï¼Œè¿™é‡Œç§æ‰¾åˆ°çš„æœ€ä¼˜è¶…å‚æ•°æ­£å¥½æ˜¯è®©knnçš„kä¸º1ï¼Œæ‰€ä»¥è¿™ä¸ªæƒ…å†µä¸‹distanceæ–¹æ³•å’Œn_neighborsæ–¹æ³•æ²¡æœ‰åŒºåˆ«ã€‚æŒ‰ç…§è°·æ­Œè°ƒå‚æ‰‹å†Œçš„ç§‘ç ”æ–¹æ³•ï¼Œå¯¹äºè¿™ä¸ªæ•°æ®é›†æ¥è¯´å°±æ— æ³•è¯´æ˜è¿™ä¸¤ä¸ªæ–¹æ³•çš„ä¼˜åŠ£äº†ã€‚

ç„¶è€Œï¼Œæˆ‘ä¸ªäººè®¤ä¸ºï¼Œä¸€ä¸ªæ–¹æ³•ä¹‹æ‰€ä»¥è¢«å­¦æœ¯ç•Œè®¤ä¸ºæœ‰ä»·å€¼ï¼Œåœ¨äºè¿™ä¸ªæ–¹æ³•èƒ½è¢«å…¶ä»–äººfollowå’Œciteã€‚ä»€ä¹ˆæ ·çš„æ–¹æ³•èƒ½å¯¹å…¶ä»–äººçš„å·¥ä½œæœ‰å¸®åŠ©ï¼Œä»€ä¹ˆæ ·çš„æ–¹æ³•å°±æœ‰ä»·å€¼ã€‚å½¢å¼åŒ–ä¸€ç‚¹æ¥è¯´ï¼Œå¯¹ â€œå…¶ä»–äººçš„å·¥ä½œâ€è¿™ä¸ªéšæœºåˆ†å¸ƒè€Œè¨€ï¼Œæˆ‘ä»¬çš„æ–¹æ³•â€œåº”ç”¨ä¸Šå»ä¹‹åï¼Œæ¯”ä¸åº”ç”¨æˆ‘ä»¬çš„æ–¹æ³•æˆ–è€…ä½¿ç”¨å…¶ä»–æ–¹æ³•æ›´å¥½â€è¿™ä¸ªéšæœºå˜é‡çš„æœŸæœ›å€¼å°±æ˜¯æˆ‘ä»¬åšç§‘ç ”åº”è¯¥è¿½æ±‚çš„ä»·å€¼ã€‚

éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œâ€œå…¶ä»–äººçš„å·¥ä½œâ€ç”±äºä»–ä»¬è®¡ç®—èµ„æºä»¥åŠç ”ç©¶è€…è®¤çŸ¥çš„å±€é™ï¼Œæ˜¯æ¯”è¾ƒä¸å¯èƒ½ä¸ºä½ çš„æ–¹æ³•è°ƒæ•´æ•´ä¸ªå®éªŒæµç¨‹å…¶ä»–çš„å…ƒå‚æ•°æˆ–è€…è¯´æ— å…³å˜é‡çš„ã€‚æ¢å¥è¯è¯´ï¼Œå¦‚æœä½ çš„æ–¹æ³•éœ€è¦å…¶ä»–äººä¸ºä½ çš„æ–¹æ³•æ¥è°ƒå‚æ‰èƒ½è¡¨ç°è‰¯å¥½ï¼Œé‚£ä¹ˆä½ çš„æ–¹æ³•çš„ä»·å€¼å…¶å®ä¹Ÿæ˜¯æ¯”è¾ƒæœ‰é™çš„ã€‚

åœ¨è¿™é‡Œæˆ‘ä»¬å°±é‡åˆ°è¿™ä¸ªæƒ…å†µï¼Œåœ¨å¤§éƒ¨åˆ†éšæœºçš„æ— å…³å˜é‡ä¸Šï¼Œæˆ‘ä»¬çœ‹åˆ°å‡è®¾æ£€éªŒæ‹’ç»äº†é›¶å‡è®¾ï¼Œè¯´æ˜distanceæ–¹æ³•æœŸæœ›åœ°æ¥è¯´æ˜¯å¯¹å…¶ä»–ç ”ç©¶äººå‘˜æœ‰å¸®åŠ©çš„ï¼Œç„¶è€Œå½“è°ƒå‚åˆ°æœ€ä¼˜æ—¶ï¼Œä»–ä»¬åˆéƒ½èƒ½è¾¾åˆ°æœ€å¥½ã€‚

ç°åœ¨æˆ‘ä»¬å›ç­”ç¬¬äºŒä¸ªé—®é¢˜ï¼Œè¿™ä¸¤ä¸ªæ–¹æ³•åˆ†åˆ«å¯¹å…¶ä»–å…ƒå‚æ•°çš„æ•æ„Ÿæ€§å¦‚ä½•?
é¦–å…ˆåˆ†æå¯¹n_neighborsçš„æ•æ„Ÿæ€§ã€‚è¿™ä¸ªæ˜¯é€šè¿‡quasi random searché‡‡æ ·çš„ã€‚

::: {#cell-56 .cell vscode='{"languageId":"python"}'}
``` {.python .cell-code}
import copy
```
:::


---

[source](https://github.com/Open-Book-Studio/THU-Coursework-Machine-Learning-for-Big-Data/blob/main/thu_big_data_ml/tree.py#L171){target="_blank" style="float:right; font-size:smaller"}

### regplot

>      regplot (*args, line_kws=None, marker=None, scatter_kws=None, **kwargs)


::: {#cell-fig-n_neighbors .cell vscode='{"languageId":"python"}'}
``` {.python .cell-code}
f = plt.figure()
ax = f.add_subplot(1,1,1)
line_dict = {}
for name, group in grouped:
    # plt.scatter(group['config/n_neighbors'], group['mean_score'], label=name)
    # p = sns.regplot(x='config/n_neighbors', y='mean_score', data=dfi, fit_reg=True, ax=ax)
    k, b = regplot(x='config/n_neighbors', y='mean_score', data=group, label=name, fit_reg=True)
    line_dict[name] = (k, b)
    

# sns.lmplot(x='config/n_neighbors', y='mean_score', data=dfi, hue="config/weights", fit_reg=True)
# ä½¿ç”¨æ•´æ•°xåæ ‡è½´
plt.xticks(range(1, 21))
# plt.xlabel('n_neighbors')
# plt.ylabel('mean_score')
plt.legend()
# plt.title("Relationship between n_neighbors and mean_score")
plt.show()
# p.get_lines()[0].get_xdata(), p.get_lines()[0].get_ydata()
for name, (k, b) in line_dict.items():
    print(f"For {name}, the regression line is y = {k:.2e}x + {b:.2e}")
```

::: {.cell-output .cell-output-display}
![Relationship between n_neighbors and mean_score](kd_tree_files/figure-html/fig-n_neighbors-output-1.png){#fig-n_neighbors fig-alt='åœ¨å›¾ä¸­æˆ‘ä»¬ç”»å‡ºäº†æ‹Ÿåˆçš„ç›´çº¿ä»¥åŠä¹‹å‰çš„95%ç½®ä¿¡åŒºé—´ã€‚'}
:::

::: {.cell-output .cell-output-stdout}
```
For distance, the regression line is y = -9.18e-04x + 9.87e-01
For uniform, the regression line is y = -9.86e-04x + 9.84e-01
```
:::
:::


ä»å›¾ @fig-n_neighbors ä¸­å¯ä»¥çœ‹å‡ºï¼Œåœ¨æ•°å­—è¯†åˆ«é—®é¢˜ä¸Šï¼Œæ— è®ºæ˜¯distanceæ–¹æ³•è¿˜æ˜¯uniformæ–¹æ³•ï¼Œéƒ½æ˜¯neighborsæ•°é‡è¶Šå¤šï¼Œç²¾åº¦åè€Œè¶Šä½ã€‚

ä»æ–œç‡ä¸Šæ¥çœ‹å¯èƒ½ä¼šä»¥ä¸ºè¿™ä¸ªé—®é¢˜å¾ˆå°ï¼Œåªæ˜¯ç¨å¾®å‡å°‘äº†ç²¾åº¦ï¼Œä½†æ˜¯ä»è§†è§‰ä¸Šå¥½åƒç¡®å®ä¸‹é™åœ°å¾ˆæ˜æ˜¾ã€‚æˆ‘ä»¬ä¸ºäº†ä»ç»Ÿè®¡ä¸Šè¯´æ˜æ¸…æ¥šåˆ°åº•ä¸‹é™åœ°æ˜¾ä¸æ˜¾è‘—ï¼Œå¯ä»¥è¿›ä¸€æ­¥é€šè¿‡çš®å°”æ£®ç›¸å…³ç³»æ•°ä»¥åŠæ–¯çš®å°”æ›¼ç›¸å…³ç³»æ•°å¯¹åº”çš„å‡è®¾æ£€éªŒæ¥éªŒè¯è¿™ä¸ªé—®é¢˜ã€‚

::: {#cell-60 .cell vscode='{"languageId":"python"}'}
``` {.python .cell-code}
from scipy.stats import pearsonr, spearmanr
```
:::


::: {#cell-61 .cell vscode='{"languageId":"python"}'}
``` {.python .cell-code}
def test_correlation_with(x, y, data, test_func, alpha=0.05):
    correlation, p_value = test_func(data[x], data[y])
    print(f"{test_func.__name__}  correlation coefficient: between {x} and {y}: {correlation}, p-value: {p_value}")
    if p_value < alpha:
        print("The correlation is significant!")
    else:
        print("The correlation is not significant.")

test_correlation_with('config/n_neighbors', 'mean_score', dfi, pearsonr)
test_correlation_with('config/n_neighbors', 'mean_score', dfi, spearmanr)
```

::: {.cell-output .cell-output-stdout}
```
pearsonr  correlation coefficient: between config/n_neighbors and mean_score: -0.8148057329177487, p-value: 6.1435506488484e-25
The correlation is significant!
spearmanr  correlation coefficient: between config/n_neighbors and mean_score: -0.8085147488740115, p-value: 2.6833127946483235e-24
The correlation is significant!
```
:::
:::


### é™„åŠ ä»»åŠ¡: å°è¯•ä½¿â½¤ä¸åŒçš„ç­–ç•¥æ¥æ„å»º KD æ ‘ï¼Œä½¿å¾—åœ¨åˆ†ç±»é˜¶æ®µå¯ä»¥æœ‰æ›´å¿«çš„åˆ†ç±»æ•ˆç‡

æ³¨æ„æˆ‘ä»¬è¿™é‡Œæ¢ç´¢è¦ä¿®æ”¹çš„ç›®æ ‡æ˜¯æ„å»º KD æ ‘çš„è¿‡ç¨‹ï¼Œä¹Ÿå°±æ˜¯è¦æ”¹å˜KDæ ‘çš„ç»“æ„ï¼Œè€Œä¸æ˜¯ä¿®æ”¹KNNåˆ†ç±»ç®—æ³•ï¼Œä¸»è¦ä¹Ÿä¸æ˜¯ä¿®æ”¹KDæ ‘çš„æœç´¢ç®—æ³•ã€‚
è¿™é‡Œæˆ‘ä»¬çš„ç›®æ ‡æ˜¯è®©æœç´¢çš„æ•ˆç‡æ›´é«˜ã€‚

æ–‡çŒ®@KD-meansä¸­æ€»ç»“äº†KDæ ‘æ„é€ æ—¶çš„ä¸€äº›å¸¸è§ç­–ç•¥ï¼Œå…¶ä¸­æœ€é‡è¦çš„å°±æ˜¯splitting methodã€‚åˆ†å‰²ä¸€ä¸ªçˆ¶èŠ‚ç‚¹çš„æ—¶å€™ï¼Œæˆ‘ä»¬éœ€è¦å†³å®š1. åœ¨å“ªä¸ªæ•°æ®ç»´åº¦ï¼ˆğ‘ ğ‘‘ï¼‰ä¸Šè¿›è¡Œåˆ’åˆ† 2. è¿™ä¸ªç»´åº¦ä¸Šå“ªä¸ªå€¼ä½œä¸ºåˆ’åˆ†ç‚¹ã€‚å¯¹äºç¬¬ä¸€ç‚¹ï¼Œä½œè€…é€‰æ‹©èŒƒå›´æœ€å¹¿çš„ç»´åº¦ï¼ˆğ‘šğ‘ğ‘¥ âˆ’ ğ‘šğ‘–ğ‘›ï¼‰æ¥è¿›è¡Œåˆ’åˆ†ã€‚

å¯¹äºç¬¬äºŒç‚¹ï¼Œä½œè€…é€‰æ‹©äº†æ»‘åŠ¨ä¸­ç‚¹åˆ†å‰²è§„åˆ™ï¼Œå› ä¸ºå®ƒæ¯”å…¶ä»–ç»å…¸è§„åˆ™æä¾›äº†æ›´ä¼˜åŒ–çš„æ•°æ®ç»„ç»‡ã€‚è¿™ç§è§„åˆ™ä¸ä¼šäº§ç”Ÿç©ºèŠ‚ç‚¹æˆ–æ•°æ®ç©ºé—´éå¸¸ç¨€ç–çš„èŠ‚ç‚¹ã€‚ä¸é€‰æ‹©ä¸­ä½æ•°ä½œä¸ºåˆ‡å‰²å€¼çš„ç»å…¸è§„åˆ™ä¸åŒï¼Œæ»‘åŠ¨ä¸­ç‚¹åˆ†å‰²è§„åˆ™é€‰æ‹©ç‚¹çš„ä¸­é—´å€¼ï¼ˆï¼ˆæœ€å¤§å€¼ğ‘šğ‘ğ‘¥ + æœ€å°å€¼ğ‘šğ‘–ğ‘›ï¼‰/ 2ï¼‰ï¼Œè¿™æ ·åšæˆæœ¬æ›´ä½ã€‚

ä½œè€…è¿˜æåˆ°KDæ ‘çš„æ„å»ºè¿‡ç¨‹ä¸­å¯ä»¥é™åˆ¶KDæ ‘çš„æ·±åº¦ã€‚ä½†æ˜¯æˆ‘ä¸å¤ªæ‡‚å¦‚æœé™åˆ¶äº†æ·±åº¦ï¼Œä¸æ˜¯å¶å­èŠ‚ç‚¹çš„åœ°æ–¹åœ¨æœç´¢æ—¶åº”è¯¥å¦‚ä½•å¤„ç†ï¼Œé€€åŒ–ä¸ºæš´åŠ›å—ï¼Ÿ

åœ¨æˆ‘ä»¬å®ç°æ–°çš„ç®—æ³•ä¹‹å‰ï¼Œæˆ‘ä»¬é¦–å…ˆæµ‹è¯•ä¸€ä¸‹æ²¡æ”¹è¿›ä¹‹å‰çš„ç®—æ³•çš„é€Ÿåº¦ã€‚

::: {#cell-65 .cell vscode='{"languageId":"python"}'}
``` {.python .cell-code}

```

::: {.cell-output .cell-output-stdout}
```
5.07 s Â± 100 ms per loop (mean Â± std. dev. of 7 runs, 1 loop each)
```
:::
:::


ç°åœ¨æˆ‘ä»¬æ¥å®ç°æ›´å¿«çš„KDæ ‘ã€‚

::: {#cell-67 .cell vscode='{"languageId":"python"}'}
``` {.python .cell-code}
# å¤ç”¨ä¸Šé¢çš„ä¸€äº›å®šä¹‰
Node, euclidean_distance
```

::: {.cell-output .cell-output-display}
```
(__main__.Node, <function __main__.euclidean_distance(x1, x2)>)
```
:::
:::


---

[source](https://github.com/Open-Book-Studio/THU-Coursework-Machine-Learning-for-Big-Data/blob/main/thu_big_data_ml/tree.py#L205){target="_blank" style="float:right; font-size:smaller"}

### fast_build_kd_tree

>      fast_build_kd_tree (X, axis_order_list:list, strategy='median', depth=0)


---

[source](https://github.com/Open-Book-Studio/THU-Coursework-Machine-Learning-for-Big-Data/blob/main/thu_big_data_ml/tree.py#L242){target="_blank" style="float:right; font-size:smaller"}

### fast_search_kd_tree

>      fast_search_kd_tree (tree, target, axis_order_list:list, k=3)


---

[source](https://github.com/Open-Book-Studio/THU-Coursework-Machine-Learning-for-Big-Data/blob/main/thu_big_data_ml/tree.py#L311){target="_blank" style="float:right; font-size:smaller"}

### FastKDTree

>      FastKDTree (X, split_value_strategy='median',
>                  axis_order_strategy='range')

*Initialize self.  See help(type(self)) for accurate signature.*


æˆ‘ä»¬å‘ç°å¦‚æœæ˜¯ç”¨middleç­–ç•¥ï¼Œç”±äºæ•°å­—è¯†åˆ«æ•°æ®é›†çš„åˆ†å¸ƒç‰¹æ€§ï¼Œä¸­ç‚¹èƒ½åˆ’åˆ†çš„ç‚¹å¤ªå°‘ï¼Œæ— æ³•æˆåŠŸå»ºæ ‘ã€‚

::: {#cell-72 .cell vscode='{"languageId":"python"}'}
``` {.python .cell-code}
# tree = FastKDTree(X, split_value_strategy="median")
tree = FastKDTree(X_train, split_value_strategy="median")
```

::: {.cell-output .cell-output-stdout}
```
[ 0 32 39 31 24 56 16  8 40 47 48 23  1 57 15 55 33 38  7  9 30 25 10  4
 14 13 12 11  6  5  3  2 28 29 26 27 19 20 21 22 17 18 42 41 36 37 35 34
 46 45 44 43 51 52 50 49 54 53 58 59 60 61 62 63]
```
:::
:::


::: {#cell-73 .cell vscode='{"languageId":"python"}'}
``` {.python .cell-code}
for i in range(len(X_train)):
    k_nearest = tree.search_kd_tree(X_train[0], 1)
    where = np.where((X_train == k_nearest[0]).all(axis=1))
    where = where[0]
    assert len(where) == 1
```
:::


::: {#cell-74 .cell vscode='{"languageId":"python"}'}
``` {.python .cell-code}
# k_nearest = tree.search_kd_tree(X_test[0], 2)
# k_nearest = tree.search_kd_tree(X_train[0], 2)
# k_nearest, X_train[0]
# k_nearest = tree.search_kd_tree(X_test[0], 2)
# k_nearest
y_pred = tree.knn_classifier(X_train, y_train, X_test, k_neighbors)
accuracy_score(y_test, y_pred) # ç¡®ä¿æ•°å€¼æ­£ç¡®
```

::: {.cell-output .cell-output-display}
```
0.9861111111111112
```
:::
:::


::: {#cell-75 .cell vscode='{"languageId":"python"}'}
``` {.python .cell-code}

```

::: {.cell-output .cell-output-stdout}
```
5.15 s Â± 107 ms per loop (mean Â± std. dev. of 7 runs, 1 loop each)
```
:::
:::


æˆ‘ä»¬å‘ç°é€Ÿåº¦å˜æ…¢äº†ï¼
å¦‚æœä½¿ç”¨æ–¹å·®æœ€å¤§ç­–ç•¥å‘¢ï¼Ÿä¼šä¸ä¼šæ›´å¥½ï¼Ÿ

::: {#cell-77 .cell vscode='{"languageId":"python"}'}
``` {.python .cell-code}
tree = FastKDTree(X_train, split_value_strategy="median", axis_order_strategy='variance')
y_pred = tree.knn_classifier(X_train, y_train, X_test, k_neighbors)
accuracy_score(y_test, y_pred) # ç¡®ä¿æ•°å€¼æ­£ç¡®
```

::: {.cell-output .cell-output-stdout}
```
[ 0 32 39 56 24 16 31  8 40 48 47 23 15  1 57 55  7 63 49 41 25  9 22  6
 33 17 38 14 30 11 62  3 46  4 59  2 12 54 60 58 51 52 10 45 50  5 18 19
 37 29 61 36 27 53 13 28 26 20 21 35 34 44 43 42]
```
:::

::: {.cell-output .cell-output-display}
```
0.9861111111111112
```
:::
:::


::: {#cell-78 .cell vscode='{"languageId":"python"}'}
``` {.python .cell-code}

```

::: {.cell-output .cell-output-stdout}
```
5.5 s Â± 217 ms per loop (mean Â± std. dev. of 7 runs, 1 loop each)
```
:::
:::


ç”šè‡³æ›´æ…¢ï¼ä¸ºäº†é¿å…æ˜¯å› ä¸ºæˆ‘ä»¬å®ç°æ–°çš„æ–¹æ³•æœ‰ä¸€å®šçš„overheadï¼Œæˆ‘ä»¬å¯¹åŸæœ¬çš„åˆ’åˆ†ç­–ç•¥ä¹Ÿåšä¸€æ¬¡æµ‹é€Ÿã€‚

::: {#cell-80 .cell vscode='{"languageId":"python"}'}
``` {.python .cell-code}
tree = FastKDTree(X_train, split_value_strategy="median", axis_order_strategy='simple')
```

::: {.cell-output .cell-output-stdout}
```
[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]
5.37 s Â± 310 ms per loop (mean Â± std. dev. of 7 runs, 1 loop each)
```
:::
:::


::: {#cell-81 .cell vscode='{"languageId":"python"}'}
``` {.python .cell-code}
y_pred = tree.knn_classifier(X_train, y_train, X_test, k_neighbors)
accuracy_score(y_test, y_pred) # ç¡®ä¿æ•°å€¼æ­£ç¡®
```

::: {.cell-output .cell-output-display}
```
0.9861111111111112
```
:::
:::


æ ¹æ®ä»¥ä¸Šç»“æœï¼Œæˆ‘ä»¬åˆæ­¥å¾—å‡ºç»“è®ºï¼Œrangeåˆ’åˆ†æ–¹æ³•æ¯”simpleæ–¹æ³•å¿«ï¼Œè€Œsimpleæ–¹æ³•æ¯”varianceæ–¹æ³•å¿«ã€‚

