@book{LiHang_2019, title={ç»Ÿè®¡å­¦ä¹ æ–¹æ³• (ç¬¬2ç‰ˆ)}, ISBN={978-7-302-51727-6}, url={https://book.douban.com/subject/33437381/}, publisher={<a href="https://book.douban.com/press/2562">æ¸…åå¤§å­¦å‡ºç‰ˆç¤¾</a>    <br>                                                      <span class="pl">å‡ºç‰ˆå¹´:</span> 2019-5}, author={æèˆª}, year={2019}, month=may, language={zh} }
@book{LiHang_2022, title={æœºå™¨å­¦ä¹ æ–¹æ³•}, ISBN={978-7-302-59730-8}, url={https://book.douban.com/subject/35884788/}, abstractNote={æœºå™¨å­¦ä¹ æ˜¯ä»¥æ¦‚ç‡è®ºã€ç»Ÿè®¡å­¦ã€ä¿¡æ¯è®ºã€æœ€ä¼˜åŒ–ç†è®ºã€è®¡ç®—ç†è®ºç­‰ä¸ºåŸºç¡€çš„è®¡ç®—æœºåº”ç”¨ç†è®ºå­¦ç§‘ï¼Œä¹Ÿæ˜¯äººå·¥æ™ºèƒ½ã€æ•°æ®æŒ–æ˜ç­‰é¢†åŸŸçš„åŸºç¡€å­¦ç§‘ã€‚, ã€Šæœºå™¨å­¦ä¹ æ–¹æ³•ã€‹å…¨é¢ç³»ç»Ÿåœ°ä»‹ç»äº†æœºå™¨å­¦ä¹ çš„ä¸»è¦æ–¹æ³•ï¼Œå…±åˆ†ä¸‰ç¯‡ã€‚ç¬¬ä¸€ç¯‡ä»‹ç»ç›‘ç£å­¦ä¹ çš„ä¸»è¦æ–¹æ³•ï¼ŒåŒ…æ‹¬æ„ŸçŸ¥æœºã€kè¿‘é‚»æ³•ã€æœ´ç´ è´å¶æ–¯æ³•ã€å†³ç­–æ ‘ã€é€»è¾‘æ–¯è°›å›å½’ä¸æœ€å¤§ç†µæ¨¡å‹ã€æ”¯æŒå‘é‡æœºã€Boostingã€EMç®—æ³•ã€éšé©¬å°”å¯å¤«æ¨¡å‹ã€æ¡ä»¶éšæœºåœºç­‰ï¼›ç¬¬äºŒç¯‡ä»‹ç»æ— ç›‘ç£å­¦ä¹ çš„ä¸»è¦æ–¹æ³•ï¼ŒåŒ…æ‹¬èšç±»ã€å¥‡å¼‚å€¼åˆ†è§£ã€ä¸»æˆåˆ†åˆ†æã€æ½œåœ¨è¯­ä¹‰åˆ†æã€æ¦‚ç‡æ½œåœ¨è¯­ä¹‰åˆ†æã€é©¬å°”å¯å¤«é“¾è’™ç‰¹å¡ç½—æ³•ã€æ½œåœ¨ç‹„åˆ©å…‹é›·åˆ†é…ã€PageRank ç®—æ³•ç­‰ã€‚ç¬¬ä¸‰ç¯‡ä»‹ç»æ·±åº¦å­¦ä¹ çš„ä¸»è¦æ–¹æ³•ï¼ŒåŒ…æ‹¬å‰é¦ˆç¥ç»ç½‘ç»œã€å·ç§¯ç¥ç»ç½‘ç»œã€å¾ªç¯ç¥ç»ç½‘ç»œã€åºåˆ—åˆ°åºåˆ—æ¨¡å‹ã€é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹ã€ç”Ÿæˆå¯¹æŠ—ç½‘ç»œç­‰ã€‚, ä¹¦ä¸­æ¯ç« ä»‹ç»ä¸€ä¸¤ç§æœºå™¨å­¦ä¹ æ–¹æ³•ï¼Œè¯¦ç»†å™è¿°å„ä¸ªæ–¹æ³•çš„æ¨¡å‹ã€ç­–ç•¥å’Œç®—æ³•ã€‚ä»å…·ä½“ä¾‹å­å…¥æ‰‹ï¼Œç”±æµ…å…¥æ·±ï¼Œå¸®åŠ©è¯»è€…ç›´è§‚åœ°ç†..., (å±•å¼€å…¨éƒ¨), æèˆªï¼Œå­—èŠ‚è·³åŠ¨ç§‘æŠ€æœ‰é™å…¬å¸äººå·¥æ™ºèƒ½å®éªŒå®¤æ€»ç›‘ï¼ŒIEEEä¼šå£«ã€ACLä¼šå£«ã€ACMæ°å‡ºç§‘å­¦å®¶ã€CCFæ°å‡ºä¼šå‘˜ã€‚ç ”ç©¶æ–¹å‘åŒ…æ‹¬ä¿¡æ¯æ£€ç´¢ã€è‡ªç„¶è¯­è¨€å¤„ç†ã€ç»Ÿè®¡æœºå™¨å­¦ä¹ åŠæ•°æ®æŒ–æ˜ã€‚, æèˆªäº1988å¹´ä»æ—¥æœ¬äº¬éƒ½å¤§å­¦ç”µæ°”å·¥ç¨‹ç³»æ¯•ä¸šï¼Œ1998å¹´è·å¾—æ—¥æœ¬ä¸œäº¬å¤§å­¦è®¡ç®—æœºç§‘å­¦åšå£«ã€‚ä»–1990å¹´è‡³2001å¹´å°±èŒäºæ—¥æœ¬NECå…¬å¸ä¸­å¤®ç ”ç©¶æ‰€ï¼Œä»»ç ”ç©¶å‘˜ï¼›2001å¹´è‡³2012å¹´å°±èŒäºå¾®è½¯äºšæ´²ç ”ç©¶é™¢ï¼Œä»»é«˜çº§ç ”ç©¶å‘˜ä¸ä¸»ä»»ç ”ç©¶å‘˜ï¼›2012å¹´è‡³2017å¹´å°±èŒäºåä¸ºæŠ€æœ¯æœ‰é™å…¬å¸è¯ºäºšæ–¹èˆŸå®éªŒå®¤ï¼Œä»»é¦–å¸­ç§‘å­¦å®¶ã€ä¸»ä»»ã€‚, æèˆªä¸€ç›´æ´»è·ƒåœ¨ç›¸å…³å­¦æœ¯é¢†åŸŸï¼Œæ›¾å‡ºç‰ˆè¿‡å››éƒ¨å­¦æœ¯ä¸“è‘—ï¼Œå¹¶åœ¨å›½é™…å­¦æœ¯ä¼šè®®å’Œå›½é™…å­¦æœ¯æœŸåˆŠä¸Šå‘è¡¨è¿‡120å¤šç¯‡å­¦æœ¯è®ºæ–‡ï¼ŒåŒ…æ‹¬ SIGIRã€WWWã€WSDMã€ACLã€EMNLPã€ICMLã€NIPSã€SIGKDDã€AAAIã€IJCAIï¼Œä»¥åŠ NLEã€JMLRã€TOISã€IRJã€IPMã€TKDEã€TWE..., (å±•å¼€å…¨éƒ¨)}, publisher={<a href="https://book.douban.com/press/2562">æ¸…åå¤§å­¦å‡ºç‰ˆç¤¾</a>    <br>                                                      <span class="pl">å‡ºç‰ˆå¹´:</span> 2022-3}, author={æèˆª}, year={2022}, month=mar, language={zh} }
@article{Rabiner_1989, title={A tutorial on hidden Markov models and selected applications in speech recognition}, volume={77}, ISSN={1558-2256}, DOI={10.1109/5.18626}, abstractNote={This tutorial provides an overview of the basic theory of hidden Markov models (HMMs) as originated by L.E. Baum and T. Petrie (1966) and gives practical details on methods of implementation of the theory along with a description of selected applications of the theory to distinct problems in speech recognition. Results from a number of original sources are combined to provide a single source of acquiring the background required to pursue further this area of research. The author first reviews the theory of discrete Markov chains and shows how the concept of hidden states, where the observation is a probabilistic function of the state, can be used effectively. The theory is illustrated with two simple examples, namely coin-tossing, and the classic balls-in-urns system. Three fundamental problems of HMMs are noted and several practical techniques for solving these problems are given. The various types of HMMs that have been studied, including ergodic as well as left-right models, are described.<>}, note={14240 citations (Crossref) [2024-12-07]}, number={2}, journal={Proceedings of the IEEE}, author={Rabiner, L.R.}, year={1989}, month=feb, pages={257â€“286}, language={en} }
@inproceedings{Zhang_2024, title={Adaptable Logical Control for Large Language Models}, url={https://openreview.net/forum?id=58X9v92zRd&referrer=%5Bthe%20profile%20of%20Honghua%20Zhang%5D(%2Fprofile%3Fid%3D~Honghua_Zhang1)}, abstractNote={Despite the success of Large Language Models (LLMs) on various tasks following human instructions, controlling model generation to follow strict constraints at inference time poses a persistent challenge. In this paper, we introduce Ctrl-G, a neuro-symbolic framework that enables tractable and adaptable control of LLM generation to follow logical constraints reliably. Ctrl-G combines any production-ready LLM with a Hidden Markov Model (HMM), guiding LLM outputs to adhere to logical constraints represented as deterministic finite automata. We show that Ctrl-G, when a TULU2-7B model is coupled with a 2B-parameter HMM, outperforms GPT4 in text editing: on the task of generating text insertions/continuations following logical constraints, our approach achieves over 30% higher satisfaction rate in human evaluation. When applied to medium-size language models (e.g., GPT2-large), Ctrl-G also beats its counterparts on standard benchmarks by large margins. Additionally, as a proof-of-concept study, we use Ctrl-G to assist LLM reasoning on the GSM benchmark, foreshadowing the application of Ctrl-G, as well as other constrained generation approaches, beyond traditional language generation tasks.}, author={Zhang, Honghua and Kung, Po-Nien and Yoshida, Masahiro and Broeck, Guy Van den and Peng, Nanyun}, year={2024}, month=nov, language={en} }
@misc{Stochastic_process_2024, rights={Creative Commons Attribution-ShareAlike License}, url={https://en.wikipedia.org/w/index.php?title=Stochastic_process&oldid=1257085679}, abstractNote={In probability theory and related fields, a stochastic () or random process is a mathematical object usually defined as a family of random variables in a probability space, where the index of the family often has the interpretation of time. Stochastic processes are widely used as mathematical models of systems and phenomena that appear to vary in a random manner. Examples include the growth of a bacterial population, an electrical current fluctuating due to thermal noise, or the movement of a gas molecule. Stochastic processes have applications in many disciplines such as biology, chemistry, ecology, neuroscience, physics, image processing, signal processing, control theory, information theory, computer science, and telecommunications. Furthermore, seemingly random changes in financial markets have motivated the extensive use of stochastic processes in finance.
Applications and the study of phenomena have in turn inspired the proposal of new stochastic processes. Examples of such stochastic processes include the Wiener process or Brownian motion process, used by Louis Bachelier to study price changes on the Paris Bourse, and the Poisson process, used by A. K. Erlang to study the number of phone calls occurring in a certain period of time. These two stochastic processes are considered the most important and central in the theory of stochastic processes, and were invented repeatedly and independently, both before and after Bachelier and Erlang, in different settings and countries.
The term random function is also used to refer to a stochastic or random process, because a stochastic process can also be interpreted as a random element in a function space. The terms stochastic process and random process are used interchangeably, often with no specific mathematical space for the set that indexes the random variables. But often these two terms are used when the random variables are indexed by the integers or an interval of the real line. If the random variables are indexed by the Cartesian plane or some higher-dimensional Euclidean space, then the collection of random variables is usually called a random field instead. The values of a stochastic process are not always numbers and can be vectors or other mathematical objects.
Based on their mathematical properties, stochastic processes can be grouped into various categories, which include random walks, martingales, Markov processes, LÃ©vy processes, Gaussian processes, random fields, renewal processes, and branching processes. The study of stochastic processes uses mathematical knowledge and techniques from probability, calculus, linear algebra, set theory, and topology as well as branches of mathematical analysis such as real analysis, measure theory, Fourier analysis, and functional analysis. The theory of stochastic processes is considered to be an important contribution to mathematics and it continues to be an active topic of research for both theoretical reasons and applications.}, note={Page Version ID: 1257085679}, journal={Wikipedia}, year={2024}, month=nov, language={en} }
@misc{Markov_chain_2024, rights={Creative Commons Attribution-ShareAlike License}, url={https://en.wikipedia.org/w/index.php?title=Markov_chain&oldid=1260423960}, abstractNote={In probability theory and statistics, a Markov chain or Markov process is a stochastic process describing a sequence of possible events in which the probability of each event depends only on the state attained in the previous event. Informally, this may be thought of as, â€œWhat happens next depends only on the state of affairs now.â€ A countably infinite sequence, in which the chain moves state at discrete time steps, gives a discrete-time Markov chain (DTMC). A continuous-time process is called a continuous-time Markov chain (CTMC). Markov processes are named in honor of the Russian mathematician Andrey Markov.
Markov chains have many applications as statistical models of real-world processes. They provide the basis for general stochastic simulation methods known as Markov chain Monte Carlo, which are used for simulating sampling from complex probability distributions, and have found application in areas including Bayesian statistics, biology, chemistry, economics, finance, information theory, physics, signal processing, and speech processing.
The adjectives Markovian and Markov are used to describe something that is related to a Markov process.}, note={Page Version ID: 1260423960}, journal={Wikipedia}, year={2024}, month=nov, language={en} }
@misc{Stationary_process_2024, rights={Creative Commons Attribution-ShareAlike License}, url={https://en.wikipedia.org/w/index.php?title=Stationary_process&oldid=1230037983}, abstractNote={In mathematics and statistics, a stationary process (or a strict/strictly stationary process or strong/strongly stationary process) is a stochastic process whose unconditional joint probability distribution does not change when shifted in time. Consequently, parameters such as mean and variance also do not change over time.
Since stationarity is an assumption underlying many statistical procedures used in time series analysis, non-stationary data are often transformed to become stationary. The most common cause of violation of stationarity is a trend in the mean, which can be due either to the presence of a unit root or of a deterministic trend. In the former case of a unit root, stochastic shocks have permanent effects, and the process is not mean-reverting. In the latter case of a deterministic trend, the process is called a trend-stationary process, and stochastic shocks have only transitory effects after which the variable tends toward a deterministically evolving (non-constant) mean.
A trend stationary process is not strictly stationary, but can easily be transformed into a stationary process by removing the underlying trend, which is solely a function of time. Similarly, processes with one or more unit roots can be made stationary through differencing. An important type of non-stationary process that does not include a trend-like behavior is a cyclostationary process, which is a stochastic process that varies cyclically with time.
For many applications strict-sense stationarity is too restrictive. Other forms of stationarity such as wide-sense stationarity or N-th-order stationarity are then employed. The definitions for different kinds of stationarity are not consistent among different authors (see Other terminology).}, note={Page Version ID: 1230037983}, journal={Wikipedia}, year={2024}, month=jun, language={en} }
@misc{é¦¬å¯å¤«éç¨‹_2022, rights={Creative Commons Attribution-ShareAlike License}, url={https://zh.wikipedia.org/w/index.php?title=%E9%A6%AC%E5%8F%AF%E5%A4%AB%E9%81%8E%E7%A8%8B&oldid=75013273}, abstractNote={åœ¨æ¦‚ç‡è®ºåŠç»Ÿè®¡å­¦ä¸­ï¼Œé©¬å°”å¯å¤«è¿‡ç¨‹ï¼ˆè‹±è¯­ï¼šMarkov processï¼‰æ˜¯ä¸€ä¸ªå…·å¤‡äº†é©¬å°”å¯å¤«æ€§è´¨çš„éšæœºè¿‡ç¨‹ï¼Œå› ä¸ºä¿„å›½æ•°å­¦å®¶å®‰å¾·é›·Â·é©¬å°”å¯å¤«å¾—åã€‚é©¬å°”å¯å¤«è¿‡ç¨‹æ˜¯ä¸å…·å¤‡è®°å¿†ç‰¹è´¨çš„ï¼ˆmemorylessnessï¼‰ã€‚æ¢è¨€ä¹‹ï¼Œé©¬å°”å¯å¤«è¿‡ç¨‹çš„æ¡ä»¶æ¦‚ç‡ä»…ä»…ä¸ç³»ç»Ÿçš„å½“å‰çŠ¶æ€ç›¸å…³ï¼Œè€Œä¸å®ƒçš„è¿‡å»å†å²æˆ–æœªæ¥çŠ¶æ€ï¼Œéƒ½æ˜¯ç‹¬ç«‹ã€ä¸ç›¸å…³çš„ã€‚
å…·å¤‡ç¦»æ•£çŠ¶æ€çš„é©¬å°”å¯å¤«è¿‡ç¨‹ï¼Œé€šå¸¸è¢«ç§°ä¸ºé©¬å°”å¯å¤«é“¾ã€‚é©¬å°”å¯å¤«é“¾é€šå¸¸ä½¿ç”¨ç¦»æ•£çš„æ—¶é—´é›†åˆå®šä¹‰ï¼Œåˆç§°ç¦»æ•£æ—¶é—´é©¬å°”å¯å¤«é“¾ã€‚æœ‰äº›å­¦è€…è™½ç„¶é‡‡ç”¨è¿™ä¸ªæœ¯è¯­ï¼Œä½†å…è®¸æ—¶é—´å¯ä»¥å–è¿ç»­çš„å€¼ã€‚}, note={Page Version ID: 75013273}, journal={ç»´åŸºç™¾ç§‘ï¼Œè‡ªç”±çš„ç™¾ç§‘å…¨ä¹¦}, year={2022}, month=dec, language={zh} }
@misc{æ— åæ•ˆæ€§, url={https://baike.baidu.hk/item/%E6%97%A0%E5%90%8E%E6%95%88%E6%80%A7/1135283}, abstractNote={æ— åæ•ˆæ€§æ˜¯æŒ‡å¦‚æœåœ¨æŸä¸ªé˜¶æ®µä¸Šè¿‡ç¨‹çš„çŠ¶æ€å·²çŸ¥ï¼Œåˆ™ä»æ­¤é˜¶æ®µä»¥åè¿‡ç¨‹çš„å‘å±•å˜åŒ–ä»…ä¸æ­¤é˜¶æ®µçš„çŠ¶æ€æœ‰å…³ï¼Œè€Œä¸è¿‡ç¨‹åœ¨æ­¤é˜¶æ®µä»¥å‰çš„é˜¶æ®µæ‰€ç»å†è¿‡çš„çŠ¶æ€æ— å…³ã€‚åˆ©ç”¨åŠ¨æ€è§„åˆ’æ–¹æ³•æ±‚è§£å¤šé˜¶æ®µå†³ç­–è¿‡ç¨‹é—®é¢˜ï¼Œè¿‡ç¨‹çš„çŠ¶æ€å¿…é¡»å…·å¤‡æ— åæ•ˆæ€§ã€‚}, journal={ç™¾åº¦ç™¾ç§‘}, language={zh} }
@misc{Optimal_substructure_2024, rights={Creative Commons Attribution-ShareAlike License}, url={https://en.wikipedia.org/w/index.php?title=Optimal_substructure&oldid=1234560167}, abstractNote={In computer science, a problem is said to have optimal substructure if an optimal solution can be constructed from optimal solutions of its subproblems. This property is used to determine the usefulness of greedy algorithms for a problem.  
Typically, a greedy algorithm is used to solve a problem with optimal substructure if it can be proven by induction that this is optimal at each step. Otherwise, provided the problem exhibits overlapping subproblems as well,  divide-and-conquer methods or dynamic programming may be used. If there are no appropriate greedy algorithms and the problem fails to exhibit overlapping subproblems, often a lengthy but straightforward search of the solution space is the best alternative.
In the application of dynamic programming to mathematical optimization, Richard Bellmanâ€™s Principle of Optimality is based on the idea that in order to solve a dynamic optimization problem from some starting period t to some ending period T, one implicitly has to solve subproblems starting from later dates s, where t<s<T. This is an example of optimal substructure. The Principle of Optimality is used to derive the Bellman equation, which shows how the value of the problem starting from t is related to the value of the problem starting from s.}, note={Page Version ID: 1234560167}, journal={Wikipedia}, year={2024}, month=jul, language={en} }
@misc{Markov_model_2024, rights={Creative Commons Attribution-ShareAlike License}, url={https://en.wikipedia.org/w/index.php?title=Markov_model&oldid=1235226510}, abstractNote={In probability theory, a Markov model is a stochastic model used to model pseudo-randomly changing systems. It is assumed that future states depend only on the current state, not on the events that occurred before it (that is, it assumes the Markov property). Generally, this assumption enables reasoning and computation with the model that would otherwise be intractable. For this reason, in the fields of predictive modelling and probabilistic forecasting, it is desirable for a given model to exhibit the Markov property.}, note={Page Version ID: 1235226510}, journal={Wikipedia}, year={2024}, month=jul, language={en} }
@misc{Probabilistic_automaton_2023, rights={Creative Commons Attribution-ShareAlike License}, url={https://en.wikipedia.org/w/index.php?title=Probabilistic_automaton&oldid=1141760291}, abstractNote={In mathematics and computer science, the probabilistic automaton (PA) is a generalization of the nondeterministic finite automaton; it includes the probability of a given transition into the transition function, turning it into a transition matrix. Thus, the probabilistic automaton also generalizes the concepts of a Markov chain and of a subshift of finite type. The languages recognized by probabilistic automata are called stochastic languages; these include the regular languages as a subset. The number of stochastic languages is uncountable.
The concept was introduced by Michael O. Rabin in 1963; a certain special case is sometimes known as the Rabin automaton (not to be confused with the subclass of Ï‰-automata also referred to as Rabin automata). In recent years, a variant has been formulated in terms of quantum probabilities, the quantum finite automaton.}, note={Page Version ID: 1141760291}, journal={Wikipedia}, year={2023}, month=feb, language={en} }

@book{Zhou_2016, series={æ¸…åç¤¾äººå·¥æ™ºèƒ½ç³»åˆ—}, title={æœºå™¨å­¦ä¹ }, ISBN={978-7-302-42328-7}, url={https://book.douban.com/subject/26708119/}, abstractNote={ä½œè€…ç®€ä»‹:
å‘¨å¿—åï¼Œå—äº¬å¤§å­¦æ•™æˆï¼Œè®¡ç®—æœºç§‘å­¦ä¸æŠ€æœ¯ç³»å‰¯ä¸»ä»»ï¼Œè½¯ä»¶æ–°æŠ€æœ¯å›½å®¶é‡ç‚¹å®éªŒå®¤å¸¸åŠ¡å‰¯ä¸»ä»»ï¼Œæœºå™¨å­¦ä¹ ä¸æ•°æ®æŒ–æ˜ç ”ç©¶æ‰€ï¼ˆLAMDAï¼‰æ‰€é•¿ï¼Œæ ¡ã€ç³»å­¦æœ¯å§”å‘˜ä¼šå§”å‘˜ï¼›ACMæ°å‡ºç§‘å­¦å®¶ï¼ŒIEEE Fellowï¼ŒIAPR Fellowï¼Œä¸­å›½è®¡ç®—æœºå­¦ä¼šä¼šå£«ï¼›é•¿æ±Ÿå­¦è€…ç‰¹è˜æ•™æˆï¼Œå›½å®¶æ°å‡ºé’å¹´åŸºé‡‘è·å¾—è€…ã€‚2007å¹´åˆ›å»ºå—äº¬å¤§å­¦æœºå™¨å­¦ä¹ ä¸æ•°æ®æŒ–æ˜ç ”ç©¶æ‰€ï¼ˆLAMDAï¼‰ï¼Œ2010å¹´11æœˆä»»è½¯ä»¶æ–°æŠ€æœ¯å›½å®¶é‡ç‚¹å®éªŒå®¤å¸¸åŠ¡å‰¯ä¸»ä»»ï¼Œ2013å¹´5æœˆä»»è®¡ç®—æœºç³»å‰¯ä¸»ä»»ã€‚

å†…å®¹ç®€ä»‹:
æœºå™¨å­¦ä¹ æ˜¯è®¡ç®—æœºç§‘å­¦ä¸äººå·¥æ™ºèƒ½çš„é‡è¦åˆ†æ”¯é¢†åŸŸã€‚æœ¬ä¹¦ä½œä¸ºè¯¥é¢†åŸŸçš„å…¥é—¨æ•™æï¼Œåœ¨å†…å®¹ä¸Šå°½å¯èƒ½æ¶µç›–æœºå™¨å­¦ä¹ åŸºç¡€çŸ¥è¯†çš„å„æ–¹é¢ã€‚ä¸ºäº†ä½¿å°½å¯èƒ½å¤šçš„è¯»è€…é€šè¿‡æœ¬ä¹¦å¯¹æœºå™¨å­¦ä¹ æœ‰æ‰€äº†è§£ï¼Œä½œè€…è¯•å›¾å°½å¯èƒ½å°‘åœ°ä½¿ç”¨æ•°å­¦çŸ¥è¯†ã€‚ç„¶è€Œï¼Œå°‘é‡çš„æ¦‚ç‡ã€ç»Ÿè®¡ã€ä»£æ•°ã€ä¼˜åŒ–ã€é€»è¾‘çŸ¥è¯†ä¼¼ä¹ä¸å¯é¿å…ã€‚å› æ­¤ï¼Œæœ¬ä¹¦æ›´é€‚åˆå¤§å­¦ä¸‰å¹´çº§ä»¥ä¸Šçš„ç†å·¥ç§‘æœ¬ç§‘ç”Ÿå’Œç ”ç©¶ç”Ÿï¼Œä»¥åŠå…·æœ‰ç±»ä¼¼èƒŒæ™¯çš„å¯¹æœºå™¨å­¦ä¹ æ„Ÿå…´è¶£çš„äººå£«ã€‚ä¸ºæ–¹ä¾¿è¯»è€…ï¼Œæœ¬ä¹¦é™„å½•ç»™å‡ºäº†ä¸€äº›ç›¸å…³æ•°å­¦åŸºç¡€çŸ¥è¯†ç®€ä»‹ã€‚
å…¨ä¹¦å…±16ç« ï¼Œå¤§è‡´åˆ†ä¸º3ä¸ªéƒ¨åˆ†ï¼šç¬¬1éƒ¨åˆ†ï¼ˆç¬¬1ï½3ç« ï¼‰ä»‹ç»æœºå™¨å­¦ä¹ çš„åŸºç¡€çŸ¥è¯†ï¼›ç¬¬2éƒ¨åˆ†ï¼ˆç¬¬4ï½10ç« ï¼‰è®¨è®ºä¸€äº›ç»å…¸è€Œå¸¸ç”¨çš„æœºå™¨å­¦ä¹ æ–¹æ³•ï¼ˆå†³ç­–æ ‘ã€ç¥ç»ç½‘ç»œã€æ”¯æŒå‘é‡æœºã€è´å¶æ–¯åˆ†ç±»å™¨ã€é›†æˆå­¦ä¹ ã€èšç±»ã€é™ç»´ä¸åº¦é‡å­¦ä¹ ï¼‰ï¼›ç¬¬3éƒ¨åˆ†ï¼ˆç¬¬11ï½16ç« ï¼‰ä¸ºè¿›é˜¶çŸ¥è¯†ï¼Œå†…å®¹æ¶‰åŠç‰¹å¾é€‰æ‹©ä¸ç¨€ç–å­¦ä¹ ã€è®¡ç®—å­¦ä¹ ç†è®ºã€åŠç›‘ç£å­¦ä¹ ã€æ¦‚ç‡å›¾æ¨¡å‹ã€è§„åˆ™å­¦ä¹ ä»¥åŠå¼ºåŒ–å­¦ä¹ ç­‰ã€‚å‰3ç« ä¹‹å¤–çš„åç»­å„ç« å‡ç›¸å¯¹ç‹¬ç«‹ï¼Œè¯»è€…å¯æ ¹æ®è‡ªå·±çš„å…´è¶£å’Œæ—¶é—´æƒ…å†µé€‰æ‹©ä½¿ç”¨ã€‚æ ¹æ®è¯¾æ—¶æƒ…å†µï¼Œä¸€ä¸ªå­¦æœŸçš„æœ¬ç§‘ç”Ÿè¯¾ç¨‹å¯è€ƒè™‘è®²æˆå‰9ç« æˆ–å‰10ç« ;ç ”ç©¶ç”Ÿè¯¾ç¨‹åˆ™ä¸å¦¨ä½¿ç”¨å…¨ä¹¦ã€‚
ä¹¦ä¸­é™¤ç¬¬1ç« å¤–ï¼Œæ¯ç« éƒ½ç»™å‡ºäº†åé“ä¹ é¢˜ã€‚æœ‰çš„ä¹ é¢˜æ˜¯å¸®åŠ©è¯»è€…å·©å›ºæœ¬ç« å­¦ä¹ ï¼Œæœ‰çš„æ˜¯ä¸ºäº†å¼•å¯¼è¯»è€…æ‰©å±•ç›¸å…³çŸ¥è¯†ã€‚ä¸€å­¦æœŸçš„ä¸€èˆ¬è¯¾ç¨‹å¯ä½¿ç”¨è¿™äº›ä¹ é¢˜ï¼Œå†è¾…ä»¥ä¸¤åˆ°ä¸‰ä¸ªé’ˆå¯¹å…·ä½“æ•°æ®é›†çš„å¤§ä½œä¸šã€‚å¸¦æ˜Ÿå·çš„ä¹ é¢˜åˆ™æœ‰ç›¸å½“éš¾åº¦ï¼Œæœ‰äº›å¹¶æ— ç°æˆç­”æ¡ˆï¼Œè°¨ä¾›å¯Œæœ‰è¿›å–å¿ƒçš„è¯»è€…å¯å‘æ€è€ƒã€‚
æœ¬ä¹¦å¯ä½œä¸ºé«˜ç­‰é™¢æ ¡è®¡ç®—æœºã€è‡ªåŠ¨åŒ–åŠç›¸å…³ä¸“ä¸šçš„æœ¬ç§‘ç”Ÿæˆ–ç ”ç©¶ç”Ÿæ•™æï¼Œä¹Ÿå¯ä¾›å¯¹æœºå™¨å­¦ä¹ æ„Ÿå…´è¶£çš„ç ”ç©¶äººå‘˜å’Œå·¥ç¨‹æŠ€æœ¯äººå‘˜é˜…è¯»å‚è€ƒã€‚}, note={ã€Šæœºå™¨å­¦ä¹ ã€‹;ğŸ‘©â€âš–ï¸3239;ğŸ”Ÿ8.6;88.00 å…ƒ;}, publisher={æ¸…åå¤§å­¦å‡ºç‰ˆç¤¾}, author={å‘¨å¿—å}, year={2016}, month=jan, collection={æ¸…åç¤¾äººå·¥æ™ºèƒ½ç³»åˆ—}, language={zh-CN} }
@inproceedings{Zhang_2023, title={Tractable Control for Autoregressive Language Generation}, ISSN={2640-3498}, url={https://proceedings.mlr.press/v202/zhang23g.html}, abstractNote={Despite the success of autoregressive large language models in text generation, it remains a major challenge to generate text that satisfies complex constraints: sampling from the conditional distribution ${Pr}(text{text} | alpha)$ is intractable for even the simplest lexical constraints $alpha$. To overcome this challenge, we propose to use tractable probabilistic models (TPMs) to impose lexical constraints in autoregressive text generation models, which we refer to as GeLaTo (Generating Language with Tractable Constraints). To demonstrate the effectiveness of this framework, we use distilled hidden Markov models, where we can efficiently compute ${Pr}(text{text} | alpha)$, to guide autoregressive generation from GPT2. GeLaTo achieves state-of-the-art performance on challenging benchmarks for constrained text generation (e.g., CommonGen), beating various strong baselines by a large margin. Our work not only opens up new avenues for controlling large language models but also motivates the development of more expressive TPMs.}, booktitle={Proceedings of the 40th International Conference on Machine Learning}, publisher={PMLR}, author={Zhang, Honghua and Dang, Meihua and Peng, Nanyun and Broeck, Guy Van Den}, year={2023}, month=jul, pages={40932â€“40945}, language={en} }
@article{Dang_2021, title={Juice: A Julia Package for Logic and Probabilistic Circuits}, volume={35}, ISSN={2374-3468, 2159-5399}, DOI={10.1609/aaai.v35i18.17999}, abstractNote={JUICE is an open-source Julia package providing tools for logic and probabilistic reasoning and learning based on logic circuits (LCs) and probabilistic circuits (PCs). It provides a range of efï¬cient algorithms for probabilistic inference queries, such as computing marginal probabilities (MAR), as well as many more advanced queries. Certain structural circuit properties are needed to achieve this tractability, which JUICE helps validate. Additionally, it supports several parameter and structure learning algorithms proposed in the recent literature. By leveraging parallelism (on both CPU and GPU), JUICE provides a fast implementation of circuit-based algorithms, which makes it suitable for tackling large-scale datasets and models.}, number={18}, journal={Proceedings of the AAAI Conference on Artificial Intelligence}, author={Dang, Meihua and Khosravi, Pasha and Liang, Yitao and Vergari, Antonio and Van Den Broeck, Guy}, year={2021}, month=may, pages={16020â€“16023}, language={en} }
@inproceedings{Liu_2022, title={Scaling Up Probabilistic Circuits by Latent Variable Distillation}, url={https://openreview.net/forum?id=067CGykiZTS}, abstractNote={Probabilistic Circuits (PCs) are a unified framework for tractable probabilistic models that support efficient computation of various probabilistic queries (e.g., marginal probabilities). One key challenge is to scale PCs to model large and high-dimensional real-world datasets: we observe that as the number of parameters in PCs increases, their performance immediately plateaus. This phenomenon suggests that the existing optimizers fail to exploit the full expressive power of large PCs. We propose to overcome such bottleneck by latent variable distillation: we leverage the less tractable but more expressive deep generative models to provide extra supervision over the latent variables of PCs. Specifically, we extract information from Transformer-based generative models to assign values to latent variables of PCs, providing guidance to PC optimizers. Experiments on both image and language modeling benchmarks (e.g., ImageNet and WikiText-2) show that latent variable distillation substantially boosts the performance of large PCs compared to their counterparts without latent variable distillation. In particular, on the image modeling benchmarks, PCs achieve competitive performance against some of the widely-used deep generative models, including variational autoencoders and flow-based models, opening up new avenues for tractable generative modeling. Our code can be found at https://github.com/UCLA-StarAI/LVD.}, author={Liu, Anji and Zhang, Honghua and Broeck, Guy Van den}, year={2022}, month=sep, language={en} }
@article{Xu_Luo_2021, title={Human action recognition based on mixed gaussian hidden markov model}, volume={336}, rights={https://creativecommons.org/licenses/by/4.0/}, ISSN={2261-236X}, DOI={10.1051/matecconf/202133606004}, abstractNote={Human action recognition is a challenging field in recent years. Many traditional signal processing and machine learning methods are gradually trying to be applied in this field. This paper uses a hidden Markov model based on mixed Gaussian to solve the problem of human action recognition. The model treats the observed human actions as samples which conform to the Gaussian mixture model, and each Gaussian mixture model is determined by a state variable. The training of the model is the process that obtain the model parameters through the expectation maximization algorithm. The simulation results show that the Hidden Markov Model based on the mixed Gaussian distribution can perform well in human action recognition.}, note={4 citations (Crossref) [2024-12-08]}, journal={MATEC Web of Conferences}, author={Xu, Jiawei and Luo, Qian}, editor={BarukÄiÄ‡, I.}, year={2021}, pages={06004}, language={en} }
@article{Liu_Wang_2017, title={Decoding Chinese stock market returns: Three-state hidden semi-Markov model}, volume={44}, ISSN={0927-538X}, DOI={10.1016/j.pacfin.2017.06.007}, abstractNote={In this paper, we employ a three-state hidden semi-Markov model (HSMM) to explain the time-varying distribution of the Chinese stock market returns since 2005. Our results indicate that the time-varying distribution depends on the hidden states, which are represented by three market conditions, namely the bear, sidewalk, and bull markets. We find that the inflation, the PMI, and the exchange rate are significantly related to the market conditions in China. A simple trading strategy based on expanding window decoding shows profitability with a Sharpe ratio of 1.14.}, journal={Pacific-Basin Finance Journal}, author={Liu, Zhenya and Wang, Shixuan}, year={2017}, month=sep, pages={127â€“149}, language={en} }
