# AUTOGENERATED! DO NOT EDIT! File to edit: ../../notebooks/coding_projects/digital_processing_of_speech_signals/P2_HMM/00hidden_markov_model.ipynb.

# %% auto 0
__all__ = ['HiddenMarkovModel']

# %% ../../notebooks/coding_projects/digital_processing_of_speech_signals/P2_HMM/00hidden_markov_model.ipynb 36
from fastcore.all import patch

# %% ../../notebooks/coding_projects/digital_processing_of_speech_signals/P2_HMM/00hidden_markov_model.ipynb 38
import jax.numpy as jnp
from flax import nnx # 导入 nnx 库，里面包含了一些常用的网络层
from fastcore.all import store_attr # 导入 fastcore 基础库的 store_attr 函数，用来方便地存储类的属性，这样Python面向对象写起来不那么冗长。 请 pip install fastcore。

# %% ../../notebooks/coding_projects/digital_processing_of_speech_signals/P2_HMM/00hidden_markov_model.ipynb 39
class HiddenMarkovModel(nnx.Module):
    """Hidden Markov Model

    HMM with 3 states and 2 observation categories.

    Attributes:
        ob_category (list, with length 2): observation categories
        total_states (int): number of states, default=3
        pi (array, with shape (3,)): initial state probability
        A (array, with shape (3, 3)): transition probability. A.sum(axis=1) must be all ones.
                                      A[i, j] means transition prob from state i to state j.
                                      A.T[i, j] means transition prob from state j to state i.
        B (array, with shape (3, 2)): emitting probability, B.sum(axis=1) must be all ones.
                                      B[i, k] means emitting prob from state i to observation k.

    """

    def __init__(self):
        self.ob_category = ['THU', 'PKU']  # 0: THU, 1: PKU
        self.total_states = 3
        self.pi = nnx.Param(jnp.array([0.2, 0.4, 0.4]))
        self.A = nnx.Param(jnp.array([[0.1, 0.6, 0.3],
                           [0.3, 0.5, 0.2],
                           [0.7, 0.2, 0.1]]))
        self.B = nnx.Param(jnp.array([[0.5, 0.5],
                           [0.4, 0.6],
                           [0.7, 0.3]]))

# %% ../../notebooks/coding_projects/digital_processing_of_speech_signals/P2_HMM/00hidden_markov_model.ipynb 45
@patch
def compute_likelihood_by_forward(self: HiddenMarkovModel, ob):
    """HMM Forward Algorithm.

    Args:
        ob (array, with shape(T,)): (o1, o2, ..., oT), observations

    Returns:
        fwd (array, with shape(T, 3)): fwd[t, s] means full-path forward probability torwards state s at
                                        timestep t given the observation ob[0:t+1].
                                        给定观察ob[0:t+1]情况下t时刻到达状态s的所有可能路径的概率和
        prob: the probability of HMM model generating observations.

    """
    T = ob.shape[0]
    fwd = jnp.zeros((T, self.total_states))

    # Begin Assignment

    # 初始化 t=0 时刻的前向概率
    # fwd[0, :] = self.pi * self.B[:, ob[0]] # jax 不支持 in place 复制
    fwd = fwd.at[0, :].set(self.pi * self.B[:, ob[0]])

    # 根据前向概率的递推公式计算 t=1 到 T 时刻的前向概率
    for t in range(1, T):
        for j in range(self.total_states):
            fwd = fwd.at[t, j].set(self.B[j, ob[t]] * jnp.dot(fwd[t - 1, :], self.A[:, j]))
            
    # End Assignment

    prob = fwd[-1, :].sum()

    return fwd, prob

# %% ../../notebooks/coding_projects/digital_processing_of_speech_signals/P2_HMM/00hidden_markov_model.ipynb 51
@patch
def compute_likelihood_by_backward(self:HiddenMarkovModel, ob):
    """HMM Backward Algorithm.

    Args:
        ob (array, with shape(T,)): (o1, o2, ..., oT), observations

    Returns:
        bwd (array, with shape(T, 3)): bwd[t, s] means full-path backward probability torwards state s at
                                        timestep t given the observation ob[t+1::]
                                        给定观察ob[t+1::]情况下t时刻到达状态s的所有可能路径的概率和
        prob: the probability of HMM model generating observations.

    """
    T = ob.shape[0]
    bwd = jnp.zeros((T, self.total_states))

    # Begin Assignment

    # 初始化 t == T-1 时刻到达各个状态的概率
    bwd = bwd.at[T - 1, :].set(1.0)

    # Induction step
    for t in reversed(range(T - 1)):
        for i in range(self.total_states):
            bwd = bwd.at[t, i].set(jnp.dot(bwd[t + 1, :] * self.B[:, ob[t + 1]], self.A[i, :]))

    # End Assignment

    prob = (bwd[0, :] * self.B[:, ob[0]] * self.pi).sum()

    return bwd, prob

# %% ../../notebooks/coding_projects/digital_processing_of_speech_signals/P2_HMM/00hidden_markov_model.ipynb 56
@patch
def decode_states_by_viterbi(self:HiddenMarkovModel, ob):
    """Viterbi Decoding Algorithm.

    Args:
        ob (array, with shape(T,)): (o1, o2, ..., oT), observations

    Variables:
        delta (array, with shape(T, 3)): delta[t, s] means max probability torwards state s at
                                            timestep t given the observation ob[0:t+1]
                                            给定观察ob[0:t+1]情况下t时刻到达状态s的概率最大的路径的概率
        phi (array, with shape(T, 3)): phi[t, s] means prior state s' for delta[t, s]
                                        给定观察ob[0:t+1]情况下t时刻到达状态s的概率最大的路径的t-1时刻的状态s'

    Returns:
        best_prob: the probability of the best state sequence
        best_path: the best state sequence

    """
    T = ob.shape[0]
    delta = jnp.zeros((T, self.total_states))
    #update np.int32
    phi = jnp.zeros((T, self.total_states), jnp.int32)
    best_prob, best_path = 0.0, jnp.zeros(T, dtype=jnp.int32)

    # Begin Assignment

    # 从初始状态开始
    delta = delta.at[0, :].set(self.pi * self.B[:, ob[0]])

    # 根据动态规划的公式来更新delta和phi
    for t in range(1, T):
        for j in range(self.total_states):
            d, p = max((delta[t - 1, i] * self.A[i, j] * self.B[j, ob[t]], i) for i in range(self.total_states))
            delta = delta.at[t, j].set(d)
            phi = phi.at[t, j].set(p)

    # End Assignment

    best_path = best_path.at[T-1].set(delta[T-1, :].argmax(0))
    best_prob = delta[T-1, best_path[T-1]]
    for t in reversed(range(T-1)):
        best_path = best_path.at[t].set(phi[t+1, best_path[t+1]])

    return best_prob, best_path

# %% ../../notebooks/coding_projects/digital_processing_of_speech_signals/P2_HMM/00hidden_markov_model.ipynb 60
if __name__ == "__main__":
    model = HiddenMarkovModel()
    observations = jnp.array([0, 1, 0, 1, 1])  # [THU, PKU, THU, PKU, PKU]
    fwd, p = model.compute_likelihood_by_forward(observations)
    print(p)
    print(fwd)
    bwd, p = model.compute_likelihood_by_backward(observations)
    print(p)
    print(bwd)
    prob, path = model.decode_states_by_viterbi(observations)
    print(prob)
    print(path)
